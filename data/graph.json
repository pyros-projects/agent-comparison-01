{"directed": false, "multigraph": false, "graph": {}, "nodes": [{"type": "paper", "title": "Test Paper: Machine Learning Advances", "authors": ["John Doe", "Jane Smith"], "abstract": "This is a test paper about machine learning.", "url": "https://arxiv.org/abs/test123", "summary": "A test paper", "tags": ["machine-learning", "ai", "test"], "questions_answered": ["What is ML?"], "key_findings": ["ML is useful"], "relevancy_score": 8.5, "interesting_score": 7.0, "ingested_at": "2025-11-19T14:27:32.194626", "id": "test_paper_1"}, {"type": "repository", "name": "test-ml-library", "owner": "testuser", "description": "A test machine learning library", "url": "https://github.com/testuser/test-ml-library", "stars": 0, "summary": "A test repository", "tags": ["machine-learning", "python", "test"], "questions_answered": ["How to use ML?"], "key_findings": ["Easy to use"], "relevancy_score": 7.5, "interesting_score": 6.5, "ingested_at": "2025-11-19T14:27:32.195771", "id": "test_repo_1"}, {"type": "paper", "title": "Attention Is All You Need", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin"], "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.", "arxiv_id": "1706.03762", "url": "http://arxiv.org/abs/1706.03762v7", "published_date": "2017-06-12T17:57:34+00:00", "summary": "This paper introduces the Transformer architecture, which relies entirely on attention mechanisms, removing the need for recurrence or convolution in sequence transduction tasks. The Transformer achieves state-of-the-art results in machine translation, notably improving BLEU scores on both English-to-German and English-to-French benchmarks, while significantly reducing training time. The architecture is also shown to generalize effectively to other NLP tasks such as constituency parsing.", "tags": ["Transformer", "Attention Mechanism", "Sequence Transduction", "Machine Translation", "Deep Learning", "Natural Language Processing", "Encoder-Decoder"], "questions_answered": ["Can models based solely on attention mechanisms outperform traditional RNN/CNN-based models in sequence transduction tasks?", "Is it possible to improve training efficiency and parallelization in neural machine translation?", "How well does an attention-only architecture generalize to tasks beyond translation?"], "key_findings": ["The Transformer architecture outperforms previous state-of-the-art methods on major machine translation benchmarks.", "Transformers are more parallelizable and train faster than architectures based on recurrence or convolution.", "The model generalizes well to other NLP tasks, such as English constituency parsing, with both large and limited data."], "relevancy_score": 10.0, "interesting_score": 10.0, "ingested_at": "2025-11-19T14:29:28.570971", "id": "9b76371b36c01aa26ef1590952775dcc"}, {"type": "paper", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "authors": ["Alexey Dosovitskiy", "Lucas Beyer", "Alexander Kolesnikov", "Dirk Weissenborn", "Xiaohua Zhai", "Thomas Unterthiner", "Mostafa Dehghani", "Matthias Minderer", "Georg Heigold", "Sylvain Gelly", "Jakob Uszkoreit", "Neil Houlsby"], "abstract": "While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.", "arxiv_id": "2010.11929", "url": "http://arxiv.org/abs/2010.11929v2", "published_date": "2020-10-22T17:55:59+00:00", "summary": "This paper introduces the Vision Transformer (ViT), demonstrating that a pure transformer model applied directly to sequences of image patches can match or surpass state-of-the-art convolutional neural networks (CNNs) in image classification tasks. The study shows that, when pre-trained on large datasets, ViT achieves excellent results on various benchmarks while requiring substantially fewer computational resources.", "tags": ["transformers", "vision transformer", "image classification", "deep learning", "computer vision", "attention mechanism"], "questions_answered": ["Can transformer architectures be effectively used for image recognition tasks, rivaling CNNs?", "Is it necessary to rely on convolutional networks or hybrid architectures for high-performing computer vision models?", "What are the computational requirements of transformer-based models compared to CNNs when scaled to large datasets?"], "key_findings": ["A pure transformer architecture (ViT) can achieve state-of-the-art performance on image classification benchmarks without using any convolutional layers.", "ViT models perform particularly well when pre-trained on large-scale datasets and then fine-tuned on smaller benchmarks.", "Compared to conventional CNNs, ViT requires substantially fewer computational resources to reach high performance when trained at scale."], "relevancy_score": 10.0, "interesting_score": 10.0, "ingested_at": "2025-11-19T14:29:30.764667", "id": "a6ed074c57bb5f313172b1086244fdf7"}, {"type": "paper", "id": "2797286e7c701d96f018ca16e773f1fc", "title": "ARC Is a Vision Problem!", "authors": ["Keya Hu", "Ali Cy", "Linlu Qiu", "Xiaoman Delores Ding", "Runqian Wang", "Yeyin Eva Zhu", "Jacob Andreas", "Kaiming He"], "abstract": "The Abstraction and Reasoning Corpus (ARC) is designed to promote research on abstract reasoning, a fundamental aspect of human intelligence. Common approaches to ARC treat it as a language-oriented problem, addressed by large language models (LLMs) or recurrent reasoning models. However, although the puzzle-like tasks in ARC are inherently visual, existing research has rarely approached the problem from a vision-centric perspective. In this work, we formulate ARC within a vision paradigm, framing it as an image-to-image translation problem. To incorporate visual priors, we represent the inputs on a \"canvas\" that can be processed like natural images. It is then natural for us to apply standard vision architectures, such as a vanilla Vision Transformer (ViT), to perform image-to-image mapping. Our model is trained from scratch solely on ARC data and generalizes to unseen tasks through test-time training. Our framework, termed Vision ARC (VARC), achieves 60.4% accuracy on the ARC-1 benchmark, substantially outperforming existing methods that are also trained from scratch. Our results are competitive with those of leading LLMs and close the gap to average human performance.", "arxiv_id": "2511.14761v1", "url": "http://arxiv.org/abs/2511.14761v1", "published_date": "2025-11-18T18:59:49+00:00", "summary": "This paper reframes the Abstraction and Reasoning Corpus (ARC) challenge as an image-to-image translation problem, leveraging vision architectures rather than language-centric models. By introducing Vision ARC (VARC), which uses a Vision Transformer trained from scratch on ARC data, the authors achieve state-of-the-art accuracy, rivaling leading language models and human performance.", "tags": ["ARC", "vision transformer", "image-to-image translation", "abstract reasoning", "computer vision", "test-time training", "AI benchmarks"], "questions_answered": ["Can ARC tasks be effectively addressed using vision-based, rather than language-based, models?", "How does treating ARC as an image-to-image problem affect model performance?", "Are standard vision architectures (e.g., ViT) effective for abstract reasoning tasks?"], "key_findings": ["Reframing ARC as a vision problem enables the use of image processing techniques and architectures.", "Vanilla Vision Transformer trained solely on ARC data achieves 60.4% accuracy on the ARC-1 benchmark, outperforming other scratch-trained methods.", "VARC's results are competitive with top-performing LLMs and approach average human performance."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:29:41.171770"}, {"type": "paper", "id": "572bd6e7baf81edea79b1e6c33d8502f", "title": "UniGen-1.5: Enhancing Image Generation and Editing through Reward Unification in Reinforcement Learning", "authors": ["Rui Tian", "Mingfei Gao", "Haiming Gang", "Jiasen Lu", "Zhe Gan", "Yinfei Yang", "Zuxuan Wu", "Afshin Dehghan"], "abstract": "We present UniGen-1.5, a unified multimodal large language model (MLLM) for advanced image understanding, generation and editing. Building upon UniGen, we comprehensively enhance the model architecture and training pipeline to strengthen the image understanding and generation capabilities while unlocking strong image editing ability. Especially, we propose a unified Reinforcement Learning (RL) strategy that improves both image generation and image editing jointly via shared reward models. To further enhance image editing performance, we propose a light Edit Instruction Alignment stage that significantly improves the editing instruction comprehension that is essential for the success of the RL training. Experimental results show that UniGen-1.5 demonstrates competitive understanding and generation performance. Specifically, UniGen-1.5 achieves 0.89 and 4.31 overall scores on GenEval and ImgEdit that surpass the state-of-the-art models such as BAGEL and reaching performance comparable to proprietary models such as GPT-Image-1.", "arxiv_id": "2511.14760v1", "url": "http://arxiv.org/abs/2511.14760v1", "published_date": "2025-11-18T18:59:30+00:00", "summary": "UniGen-1.5 is an advanced multimodal large language model designed to enhance image understanding, generation, and editing. By introducing a unified reinforcement learning strategy with shared reward models and an Edit Instruction Alignment stage, it significantly improves performance across these tasks, outperforming previous state-of-the-art models. The model demonstrates strong results on benchmark datasets, achieving scores competitive with leading proprietary systems.", "tags": ["multimodal models", "image generation", "image editing", "reinforcement learning", "reward unification", "LLM", "instruction alignment"], "questions_answered": ["How can image generation and editing be jointly improved using reinforcement learning?", "Can a unified reward model benefit multiple image-related tasks in multimodal AI systems?", "What methods can enhance instruction comprehension for image editing in LLMs?"], "key_findings": ["Introduced a unified RL strategy with shared reward models that jointly boosts image generation and editing performance.", "Proposed a lightweight Edit Instruction Alignment stage to improve image editing instruction comprehension, facilitating more effective RL training.", "UniGen-1.5 outperforms state-of-the-art open models like BAGEL and matches the performance of proprietary models such as GPT-Image-1 on GenEval and ImgEdit benchmarks."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:29:44.146390"}, {"type": "paper", "id": "378d41b6baf89af8bce7f266d5b08cc7", "title": "$\u03c0^{*}_{0.6}$: a VLA That Learns From Experience", "authors": ["Ali Amin", "Raichelle Aniceto", "Ashwin Balakrishna", "Kevin Black", "Ken Conley", "Grace Connors", "James Darpinian", "Karan Dhabalia", "Jared DiCarlo", "Danny Driess", "Michael Equi", "Adnan Esmail", "Yunhao Fang", "Chelsea Finn", "Catherine Glossop", "Thomas Godden", "Ivan Goryachev", "Lachy Groom", "Hunter Hancock", "Karol Hausman", "Gashon Hussein", "Brian Ichter", "Szymon Jakubczak", "Rowan Jen", "Tim Jones", "Ben Katz", "Liyiming Ke", "Chandra Kuchi", "Marinda Lamb", "Devin LeBlanc", "Sergey Levine", "Adrian Li-Bell", "Yao Lu", "Vishnu Mano", "Mohith Mothukuri", "Suraj Nair", "Karl Pertsch", "Allen Z. Ren", "Charvi Sharma", "Lucy Xiaoyang Shi", "Laura Smith", "Jost Tobias Springenberg", "Kyle Stachowicz", "Will Stoeckle", "Alex Swerdlow", "James Tanner", "Marcel Torne", "Quan Vuong", "Anna Walling", "Haohuan Wang", "Blake Williams", "Sukwon Yoo", "Lili Yu", "Ury Zhilinsky", "Zhiyuan Zhou"], "abstract": "We study how vision-language-action (VLA) models can improve through real-world deployments via reinforcement learning (RL). We present a general-purpose method, RL with Experience and Corrections via Advantage-conditioned Policies (RECAP), that provides for RL training of VLAs via advantage conditioning. Our method incorporates heterogeneous data into the self-improvement process, including demonstrations, data from on-policy collection, and expert teleoperated interventions provided during autonomous execution. RECAP starts by pre-training a generalist VLA with offline RL, which we call $\u03c0^{*}_{0.6}$, that can then be specialized to attain high performance on downstream tasks through on-robot data collection. We show that the $\u03c0^{*}_{0.6}$ model trained with the full RECAP method can fold laundry in real homes, reliably assemble boxes, and make espresso drinks using a professional espresso machine. On some of the hardest tasks, RECAP more than doubles task throughput and roughly halves the task failure rate.", "arxiv_id": "2511.14759v1", "url": "http://arxiv.org/abs/2511.14759v1", "published_date": "2025-11-18T18:58:55+00:00", "summary": "This paper introduces RL with Experience and Corrections via Advantage-conditioned Policies (RECAP), a method for continually improving vision-language-action (VLA) models through reinforcement learning with heterogeneous data sources. The authors leverage RECAP to pre-train a generalist VLA ($\u03c0^{*}_{0.6}$) and show that it can be further specialized for real-world robotic tasks, demonstrating significant performance improvements in household and manipulation tasks.", "tags": ["vision-language-action models", "reinforcement learning", "robot learning", "offline RL", "data-efficient RL", "robotic manipulation", "real-world deployment"], "questions_answered": ["How can VLA models continue to improve after deployment in the real world?", "How can diverse data sources (demonstrations, on-policy data, expert corrections) be integrated for RL training?", "Can generalist pre-trained models be specialized to excel at specific robotic tasks through further experience?"], "key_findings": ["RECAP enables effective RL training by conditioning on diverse sources of experience, including demonstrations and corrections.", "The $\u03c0^{*}_{0.6}$ model, trained with RECAP, achieves high performance on challenging real-world robotic tasks such as folding laundry, box assembly, and making espresso.", "The proposed method more than doubles task throughput and reduces failure rates by half on the most difficult tasks compared to prior approaches."], "relevancy_score": 9.0, "interesting_score": 9.0, "ingested_at": "2025-11-19T14:29:48.171080"}, {"type": "paper", "id": "a3ccb9e1076d45c90a0384672721046c", "title": "Robust Verification of Controllers under State Uncertainty via Hamilton-Jacobi Reachability Analysis", "authors": ["Albert Lin", "Alessandro Pinto", "Somil Bansal"], "abstract": "As perception-based controllers for autonomous systems become increasingly popular in the real world, it is important that we can formally verify their safety and performance despite perceptual uncertainty. Unfortunately, the verification of such systems remains challenging, largely due to the complexity of the controllers, which are often nonlinear, nonconvex, learning-based, and/or black-box. Prior works propose verification algorithms that are based on approximate reachability methods, but they often restrict the class of controllers and systems that can be handled or result in overly conservative analyses. Hamilton-Jacobi (HJ) reachability analysis is a popular formal verification tool for general nonlinear systems that can compute optimal reachable sets under worst-case system uncertainties; however, its application to perception-based systems is currently underexplored. In this work, we propose RoVer-CoRe, a framework for the Robust Verification of Controllers via HJ Reachability. To the best of our knowledge, RoVer-CoRe is the first HJ reachability-based framework for the verification of perception-based systems under perceptual uncertainty. Our key insight is to concatenate the system controller, observation function, and the state estimation modules to obtain an equivalent closed-loop system that is readily compatible with existing reachability frameworks. Within RoVer-CoRe, we propose novel methods for formal safety verification and robust controller design. We demonstrate the efficacy of the framework in case studies involving aircraft taxiing and NN-based rover navigation. Code is available at the link in the footnote.", "arxiv_id": "2511.14755v1", "url": "http://arxiv.org/abs/2511.14755v1", "published_date": "2025-11-18T18:55:20+00:00", "summary": "This paper introduces RoVer-CoRe, a novel framework using Hamilton-Jacobi reachability analysis for formal verification of perception-based controllers under state (perceptual) uncertainty. By concatenating controllers, observation, and state estimation modules, the approach makes complex perception-based systems compatible with reachability analysis, enabling robust safety verification and controller design. The framework's efficacy is demonstrated on aircraft taxiing and neural network-based rover navigation scenarios.", "tags": ["formal verification", "perception-based control", "Hamilton-Jacobi reachability", "autonomous systems", "state uncertainty", "neural network controllers"], "questions_answered": ["How can formal verification be achieved for perception-based controllers operating under state/perceptual uncertainty?", "Can Hamilton-Jacobi reachability analysis be applied to complex, nonlinear, or learning-based autonomous controllers?", "How can robust safety guarantees be provided for black-box or nonlinear controllers in autonomous systems with uncertain state estimates?"], "key_findings": ["The proposed RoVer-CoRe framework is the first to apply HJ reachability analysis for verifying perception-based controllers under state uncertainty.", "By modeling the closed-loop system including controller, perception, and state estimation as a whole, existing reachability analysis tools can be used for complex AI-driven systems.", "RoVer-CoRe enables both formal safety verification and robust controller design without overly conservative assumptions or limiting controller/system types.", "Practical case studies\u2014aircraft taxiing and neural network-based navigation\u2014demonstrate the real-world applicability of the framework."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:29:51.645462"}, {"type": "paper", "id": "173da5c7b0eae173c3edddf810aa9f4a", "title": "SparseST: Exploiting Data Sparsity in Spatiotemporal Modeling and Prediction", "authors": ["Junfeng Wu", "Hadjer Benmeziane", "Kaoutar El Maghraoui", "Liu Liu", "Yinan Wang"], "abstract": "Spatiotemporal data mining (STDM) has a wide range of applications in various complex physical systems (CPS), i.e., transportation, manufacturing, healthcare, etc. Among all the proposed methods, the Convolutional Long Short-Term Memory (ConvLSTM) has proved to be generalizable and extendable in different applications and has multiple variants achieving state-of-the-art performance in various STDM applications. However, ConvLSTM and its variants are computationally expensive, which makes them inapplicable in edge devices with limited computational resources. With the emerging need for edge computing in CPS, efficient AI is essential to reduce the computational cost while preserving the model performance. Common methods of efficient AI are developed to reduce redundancy in model capacity (i.e., model pruning, compression, etc.). However, spatiotemporal data mining naturally requires extensive model capacity, as the embedded dependencies in spatiotemporal data are complex and hard to capture, which limits the model redundancy. Instead, there is a fairly high level of data and feature redundancy that introduces an unnecessary computational burden, which has been largely overlooked in existing research. Therefore, we developed a novel framework SparseST, that pioneered in exploiting data sparsity to develop an efficient spatiotemporal model. In addition, we explore and approximate the Pareto front between model performance and computational efficiency by designing a multi-objective composite loss function, which provides a practical guide for practitioners to adjust the model according to computational resource constraints and the performance requirements of downstream tasks.", "arxiv_id": "2511.14753v1", "url": "http://arxiv.org/abs/2511.14753v1", "published_date": "2025-11-18T18:53:37+00:00", "summary": "This paper introduces SparseST, a novel framework that leverages data sparsity to improve computational efficiency in spatiotemporal modeling and prediction. Unlike previous approaches focused on reducing model capacity redundancy, SparseST exploits the inherent data and feature redundancy in spatiotemporal datasets to maintain performance while reducing computational costs. The framework incorporates a multi-objective loss function to balance performance and efficiency, enabling practical customization for edge computing scenarios.", "tags": ["spatiotemporal modeling", "data sparsity", "computational efficiency", "ConvLSTM", "efficient AI", "edge computing", "multi-objective optimization"], "questions_answered": ["How can computational efficiency in spatiotemporal data modeling be improved without sacrificing performance?", "What role does data and feature redundancy play in spatiotemporal prediction models?", "How can model design balance accuracy and resource constraints in edge-deployed AI systems?"], "key_findings": ["SparseST is the first framework to exploit data sparsity, rather than model sparsity, for efficient spatiotemporal modeling.", "Data and feature redundancy are substantial contributors to computational burden in spatiotemporal prediction, more so than model redundancy.", "A multi-objective composite loss function enables approximation of the Pareto front between model performance and efficiency, giving practitioners practical control over trade-offs.", "SparseST supports resource-adaptive deployment in edge computing environments without significant loss of accuracy."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:29:54.827774"}, {"type": "paper", "id": "0c539103d5c769e7a877ad348b4dd126", "title": "Co-Me: Confidence-Guided Token Merging for Visual Geometric Transformers", "authors": ["Yutian Chen", "Yuheng Qiu", "Ruogu Li", "Ali Agha", "Shayegan Omidshafiei", "Jay Patrikar", "Sebastian Scherer"], "abstract": "We propose Confidence-Guided Token Merging (Co-Me), an acceleration mechanism for visual geometric transformers without retraining or finetuning the base model. Co-Me distilled a light-weight confidence predictor to rank tokens by uncertainty and selectively merge low-confidence ones, effectively reducing computation while maintaining spatial coverage. Compared to similarity-based merging or pruning, the confidence signal in Co-Me reliably indicates regions emphasized by the transformer, enabling substantial acceleration without degrading performance. Co-Me applies seamlessly to various multi-view and streaming visual geometric transformers, achieving speedups that scale with sequence length. When applied to VGGT and MapAnything, Co-Me achieves up to $11.3\\times$ and $7.2\\times$ speedup, making visual geometric transformers practical for real-time 3D perception and reconstruction.", "arxiv_id": "2511.14751v1", "url": "http://arxiv.org/abs/2511.14751v1", "published_date": "2025-11-18T18:52:22+00:00", "summary": "This paper introduces Co-Me, a confidence-guided token merging method designed to accelerate visual geometric transformers without retraining or fine-tuning. By leveraging a lightweight confidence predictor to rank and merge low-confidence tokens, Co-Me reduces computational cost while preserving spatial coverage and performance. The approach enables significant speedups for various transformer-based models, making them more suitable for real-time 3D perception and reconstruction tasks.", "tags": ["token merging", "confidence estimation", "visual geometric transformers", "inference acceleration", "3D perception", "real-time reconstruction", "multi-view vision", "streaming transformers"], "questions_answered": ["How can inference speed of visual geometric transformers be increased without retraining or fine-tuning?", "What methods can reduce computational cost while maintaining spatial coverage in vision transformers?", "How does confidence-guided token merging compare to similarity-based merging or pruning?"], "key_findings": ["Co-Me uses a distilled confidence predictor to rank tokens, merging those with low confidence to accelerate inference.", "The confidence signal more reliably identifies less important regions for merging compared to similarity metrics.", "Co-Me achieves up to 11.3\u00d7 speedup on VGGT and 7.2\u00d7 speedup on MapAnything, with negligible performance loss.", "The method is broadly applicable to different multi-view and streaming transformer architectures for visual geometry tasks."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:29:58.221795"}, {"type": "paper", "id": "134fb2ca4f6218215b8f51a92f837258", "title": "Vision Large Language Models Are Good Noise Handlers in Engagement Analysis", "authors": ["Alexander Vedernikov", "Puneet Kumar", "Haoyu Chen", "Tapio Sepp\u00e4nen", "Xiaobai Li"], "abstract": "Engagement recognition in video datasets, unlike traditional image classification tasks, is particularly challenged by subjective labels and noise limiting model performance. To overcome the challenges of subjective and noisy engagement labels, we propose a framework leveraging Vision Large Language Models (VLMs) to refine annotations and guide the training process. Our framework uses a questionnaire to extract behavioral cues and split data into high- and low-reliability subsets. We also introduce a training strategy combining curriculum learning with soft label refinement, gradually incorporating ambiguous samples while adjusting supervision to reflect uncertainty. We demonstrate that classical computer vision models trained on refined high-reliability subsets and enhanced with our curriculum strategy show improvements, highlighting benefits of addressing label subjectivity with VLMs. This method surpasses prior state of the art across engagement benchmarks such as EngageNet (three of six feature settings, maximum improvement of +1.21%), and DREAMS / PAFE with F1 gains of +0.22 / +0.06.", "arxiv_id": "2511.14749v1", "url": "http://arxiv.org/abs/2511.14749v1", "published_date": "2025-11-18T18:50:26+00:00", "summary": "This paper introduces a framework that leverages Vision Large Language Models (VLMs) to handle noisy and subjective labels in video-based engagement recognition. By refining labels using behavioral questionnaires and applying a curriculum learning strategy with soft label refinement, the approach enhances classical vision models' performance. The method achieves state-of-the-art results on multiple engagement benchmarks, demonstrating VLMs' utility in managing uncertainty and noise in annotation.", "tags": ["engagement recognition", "vision large language models", "label noise handling", "curriculum learning", "soft label refinement", "video analysis", "subjective annotation"], "questions_answered": ["How can subjective and noisy engagement labels in video datasets be effectively managed?", "Can VLMs improve annotation quality and model performance in engagement recognition tasks?", "What training strategies help address uncertainty in behavioral data labeling?"], "key_findings": ["Using VLMs and behavioral questionnaires enables splitting data into high- and low-reliability subsets, leading to better annotation quality.", "A curriculum learning strategy with soft label refinement allows gradual inclusion of ambiguous samples while adjusting for uncertainty, which boosts model performance.", "The proposed method outperforms prior state-of-the-art models on several engagement analysis benchmarks, with notable improvements in F1 scores and other metrics."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:30:00.656985"}, {"type": "paper", "id": "c78bede02b7f9d72db8c0309eae56127", "title": "Look-Ahead Reasoning on Learning Platforms", "authors": ["Haiqing Zhu", "Tijana Zrnic", "Celestine Mendler-D\u00fcnner"], "abstract": "On many learning platforms, the optimization criteria guiding model training reflect the priorities of the designer rather than those of the individuals they affect. Consequently, users may act strategically to obtain more favorable outcomes, effectively contesting the platform's predictions. While past work has studied strategic user behavior on learning platforms, the focus has largely been on strategic responses to a deployed model, without considering the behavior of other users. In contrast, look-ahead reasoning takes into account that user actions are coupled, and -- at scale -- impact future predictions. Within this framework, we first formalize level-$k$ thinking, a concept from behavioral economics, where users aim to outsmart their peers by looking one step ahead. We show that, while convergence to an equilibrium is accelerated, the equilibrium remains the same, providing no benefit of higher-level reasoning for individuals in the long run. Then, we focus on collective reasoning, where users take coordinated actions by optimizing through their joint impact on the model. By contrasting collective with selfish behavior, we characterize the benefits and limits of coordination; a new notion of alignment between the learner's and the users' utilities emerges as a key concept. We discuss connections to several related mathematical frameworks, including strategic classification, performative prediction, and algorithmic collective action.", "arxiv_id": "2511.14745v1", "url": "http://arxiv.org/abs/2511.14745v1", "published_date": "2025-11-18T18:45:32+00:00", "summary": "This paper investigates how users on learning platforms strategically respond to algorithmic models, especially when users anticipate or coordinate with each other's behavior. It formalizes level-k reasoning, revealing that looking ahead accelerates convergence but does not change equilibrium outcomes, and distinguishes between selfish and collective user strategies, highlighting the importance of alignment between platform and user objectives. The study situates these concepts in the context of strategic classification, performative prediction, and algorithmic collective action.", "tags": ["Strategic behavior", "Learning platforms", "Level-k reasoning", "Game theory in ML", "Performative prediction", "Strategic classification", "Collective action", "User-model interaction"], "questions_answered": ["How do users on learning platforms act strategically when aware of the optimization criteria of deployed models?", "What impact does look-ahead (level-k) reasoning have on user outcomes and equilibrium in such systems?", "How do collective user strategies differ from selfish strategies, and what are the benefits and limits of coordination?", "How does alignment between learner and user utilities affect system outcomes?"], "key_findings": ["Formalization of level-k reasoning in the context of learning platforms, showing that higher-level reasoning speeds up equilibrium convergence but does not yield better long-term outcomes for individuals.", "Characterization of collective reasoning, revealing that coordinated user actions can lead to different system behaviors compared to selfish strategies.", "Identification of utility alignment between users and learners as a crucial factor for beneficial outcomes.", "Establishment of links between the studied framework and existing fields such as strategic classification, performative prediction, and algorithmic collective action."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:30:04.213134"}, {"type": "paper", "id": "2a10fa80141c80dd9a73f3e942315572", "title": "Measuring AI Progress in Drug Discovery: A Reproducible Leaderboard for the Tox21 Challenge", "authors": ["Antonia Ebner", "Christoph Bartmann", "Sonja Topf", "Sohvi Luukkonen", "Johannes Schimunek", "G\u00fcnter Klambauer"], "abstract": "Deep learning's rise since the early 2010s has transformed fields like computer vision and natural language processing and strongly influenced biomedical research. For drug discovery specifically, a key inflection - akin to vision's \"ImageNet moment\" - arrived in 2015, when deep neural networks surpassed traditional approaches on the Tox21 Data Challenge. This milestone accelerated the adoption of deep learning across the pharmaceutical industry, and today most major companies have integrated these methods into their research pipelines. After the Tox21 Challenge concluded, its dataset was included in several established benchmarks, such as MoleculeNet and the Open Graph Benchmark. However, during these integrations, the dataset was altered and labels were imputed or manufactured, resulting in a loss of comparability across studies. Consequently, the extent to which bioactivity and toxicity prediction methods have improved over the past decade remains unclear. To this end, we introduce a reproducible leaderboard, hosted on Hugging Face with the original Tox21 Challenge dataset, together with a set of baseline and representative methods. The current version of the leaderboard indicates that the original Tox21 winner - the ensemble-based DeepTox method - and the descriptor-based self-normalizing neural networks introduced in 2017, continue to perform competitively and rank among the top methods for toxicity prediction, leaving it unclear whether substantial progress in toxicity prediction has been achieved over the past decade. As part of this work, we make all baselines and evaluated models publicly accessible for inference via standardized API calls to Hugging Face Spaces.", "arxiv_id": "2511.14744v1", "url": "http://arxiv.org/abs/2511.14744v1", "published_date": "2025-11-18T18:43:42+00:00", "summary": "This paper establishes a reproducible leaderboard for drug toxicity prediction using the original Tox21 Challenge dataset, addressing the issue of dataset alterations in previous benchmarks. The study finds that top-performing methods from a decade ago, such as DeepTox and self-normalizing neural networks, still rank highly, raising questions about progress in AI-based toxicity prediction over the past ten years.", "tags": ["AI in drug discovery", "toxicity prediction", "deep learning", "benchmarking", "reproducibility", "leaderboards", "Tox21 Challenge"], "questions_answered": ["Has AI-driven toxicity prediction made substantial progress since the original Tox21 Challenge?", "How do classic deep learning models (like DeepTox) compare to recent methods on the original Tox21 dataset?", "How can reproducibility and comparability of results in drug discovery benchmarks be improved?"], "key_findings": ["A reproducible leaderboard for toxicity prediction was created using the original Tox21 dataset, hosted on Hugging Face.", "Original state-of-the-art models such as DeepTox and descriptor-based self-normalizing neural networks remain competitive compared to newer approaches.", "Dataset alterations in previous benchmarks have muddled comparability and assessment of progress in bioactivity and toxicity modeling.", "All evaluated models and baselines have been made publicly accessible through standardized API interfaces."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:30:07.845155"}, {"type": "paper", "id": "d2a3dc8e3568e5c807829530f5945289", "title": "Beyond Means: A Dynamic Framework for Predicting Customer Satisfaction", "authors": ["Christof Naumzik", "Abdurahman Maarouf", "Stefan Feuerriegel", "Markus Weinmann"], "abstract": "Online ratings influence customer decision-making, yet standard aggregation methods, such as the sample mean, fail to adapt to quality changes over time and ignore review heterogeneity (e.g., review sentiment, a review's helpfulness). To address these challenges, we demonstrate the value of using the Gaussian process (GP) framework for rating aggregation. Specifically, we present a tailored GP model that captures the dynamics of ratings over time while additionally accounting for review heterogeneity. Based on 121,123 ratings from Yelp, we compare the predictive power of different rating aggregation methods in predicting future ratings, thereby finding that the GP model is considerably more accurate and reduces the mean absolute error by 10.2% compared to the sample mean. Our findings have important implications for marketing practitioners and customers. By moving beyond means, designers of online reputation systems can display more informative and adaptive aggregated rating scores that are accurate signals of expected customer satisfaction.", "arxiv_id": "2511.14743v1", "url": "http://arxiv.org/abs/2511.14743v1", "published_date": "2025-11-18T18:43:29+00:00", "summary": "This paper proposes a dynamic rating aggregation method using Gaussian Process (GP) modeling to improve customer satisfaction prediction on online platforms. The GP framework accounts for temporal changes and review heterogeneity, outperforming standard sample mean approaches. Empirical evaluation on Yelp ratings demonstrates a significant reduction in prediction error and highlights the need for adaptive aggregation in reputation systems.", "tags": ["Gaussian Process", "Rating Aggregation", "Customer Satisfaction Prediction", "Online Reputation Systems", "Temporal Dynamics", "Review Heterogeneity", "Machine Learning"], "questions_answered": ["How can online rating aggregation methods adapt to changes in quality over time?", "How can models account for heterogeneity in review sentiment and helpfulness?", "Which aggregation method best predicts future customer ratings?"], "key_findings": ["The proposed tailored Gaussian Process model significantly improves prediction accuracy for future ratings compared to conventional sample mean aggregation.", "The model captures both temporal dynamics and review heterogeneity, making aggregated ratings more informative and adaptive.", "Using the GP framework reduces the mean absolute error by 10.2% when predicting future ratings from a large Yelp dataset."], "relevancy_score": 8.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:30:11.641343"}, {"type": "paper", "id": "6bfa67b614089367e3bb08d29294e43a", "title": "NeuCLIRBench: A Modern Evaluation Collection for Monolingual, Cross-Language, and Multilingual Information Retrieval", "authors": ["Dawn Lawrie", "James Mayfield", "Eugene Yang", "Andrew Yates", "Sean MacAvaney", "Ronak Pradeep", "Scott Miller", "Paul McNamee", "Luca Soldani"], "abstract": "To measure advances in retrieval, test collections with relevance judgments that can faithfully distinguish systems are required. This paper presents NeuCLIRBench, an evaluation collection for cross-language and multilingual retrieval. The collection consists of documents written natively in Chinese, Persian, and Russian, as well as those same documents machine translated into English. The collection supports several retrieval scenarios including: monolingual retrieval in English, Chinese, Persian, or Russian; cross-language retrieval with English as the query language and one of the other three languages as the document language; and multilingual retrieval, again with English as the query language and relevant documents in all three languages. NeuCLIRBench combines the TREC NeuCLIR track topics of 2022, 2023, and 2024. The 250,128 judgments across approximately 150 queries for the monolingual and cross-language tasks and 100 queries for multilingual retrieval provide strong statistical discriminatory power to distinguish retrieval approaches. A fusion baseline of strong neural retrieval systems is included with the collection so that developers of reranking algorithms are no longer reliant on BM25 as their first-stage retriever. NeuCLIRBench is publicly available.", "arxiv_id": "2511.14758v1", "url": "http://arxiv.org/abs/2511.14758v1", "published_date": "2025-11-18T18:58:19+00:00", "summary": "This paper introduces NeuCLIRBench, a comprehensive evaluation collection for monolingual, cross-language, and multilingual information retrieval tasks. The benchmark spans Chinese, Persian, Russian, and English (both native and translated), consolidating TREC NeuCLIR tracks from 2022-2024 and providing extensive relevance judgments to discriminate between retrieval systems. A strong neural fusion baseline is included to support reranking advancements beyond traditional BM25 approaches.", "tags": ["information retrieval", "cross-language retrieval", "multilingual retrieval", "evaluation benchmark", "neural retrieval", "TREC", "machine translation", "relevance judgments"], "questions_answered": ["How can retrieval systems for monolingual, cross-language, and multilingual scenarios be fairly and robustly evaluated?", "What standardized resources are available for benchmarking neural and traditional information retrieval models across multiple languages?", "How can relevance judgments be scaled across large multilingual datasets to enable fine-grained comparison between retrieval methodologies?", "What is the impact of using strong neural retrievers as baselines instead of traditional BM25 for reranking tasks?"], "key_findings": ["NeuCLIRBench offers a modern, unified evaluation collection covering monolingual, cross-language, and multilingual search scenarios for Chinese, Persian, Russian, and English.", "The dataset includes both native documents and their machine-translated English counterparts, enabling a wide range of retrieval experiments.", "The collection aggregates TREC NeuCLIR track data from three years, offering a total of 250,128 relevance judgments, providing strong statistical power for benchmarking.", "A fusion baseline using strong neural retrievers is provided, supporting more robust first-stage retrieval and enabling further advancements in reranking algorithms."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:32:41.087433"}, {"type": "paper", "id": "3b7e78a443c42259ece87f418adc2df8", "title": "HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation", "authors": ["Lai Wei", "Xuanbin Peng", "Ri-Zhao Qiu", "Tianshu Huang", "Xuxin Cheng", "Xiaolong Wang"], "abstract": "Learning from real-world robot demonstrations holds promise for interacting with complex real-world environments. However, the complexity and variability of interaction dynamics often cause purely positional controllers to struggle with contacts or varying payloads. To address this, we propose a Heterogeneous Meta-Control (HMC) framework for Loco-Manipulation that adaptively stitches multiple control modalities: position, impedance, and hybrid force-position. We first introduce an interface, HMC-Controller, for blending actions from different control profiles continuously in the torque space. HMC-Controller facilitates both teleoperation and policy deployment. Then, to learn a robust force-aware policy, we propose HMC-Policy to unify different controllers into a heterogeneous architecture. We adopt a mixture-of-experts style routing to learn from large-scale position-only data and fine-grained force-aware demonstrations. Experiments on a real humanoid robot show over 50% relative improvement vs. baselines on challenging tasks such as compliant table wiping and drawer opening, demonstrating the efficacy of HMC.", "arxiv_id": "2511.14756v1", "url": "http://arxiv.org/abs/2511.14756v1", "published_date": "2025-11-18T18:56:24+00:00", "summary": "This paper introduces Heterogeneous Meta-Control (HMC), a framework for robot loco-manipulation that adaptively combines multiple control modalities (position, impedance, hybrid force-position) in the torque space. Through the HMC-Controller interface and HMC-Policy learning architecture, the approach merges position-only and force-aware demonstration data using mixture-of-experts routing to achieve robust, real-world performance. Experiments on a humanoid robot demonstrate significant improvements over baseline methods in contact-rich tasks.", "tags": ["robot learning", "meta-control", "loco-manipulation", "force-aware control", "mixture-of-experts", "contact-rich manipulation", "robot demonstrations", "impedance control"], "questions_answered": ["How can robots robustly perform contact-rich manipulation tasks when using real-world demonstrations?", "How can different control modalities (position, impedance, hybrid force-position) be adaptively blended during policy deployment?", "How can both position-only and force-aware demonstration data be unified for learning effective loco-manipulation policies?"], "key_findings": ["The proposed HMC framework enables adaptive blending of heterogeneous control modalities in real-time torque space, improving control robustness.", "HMC-Policy leverages a mixture-of-experts approach to unify large-scale position-only data with fine-grained force-aware demonstrations, enhancing learning efficiency and generalization.", "Experimental results show over 50% relative performance improvement in challenging loco-manipulation tasks compared to baseline controllers."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:32:44.176806"}, {"type": "paper", "id": "1b5212b12c4f4ce818db1d74cb6dcafe", "title": "A Neural Field-Based Approach for View Computation & Data Exploration in 3D Urban Environments", "authors": ["Stefan Cobeli", "Kazi Shahrukh Omar", "Rodrigo Valen\u00e7a", "Nivan Ferreira", "Fabio Miranda"], "abstract": "Despite the growing availability of 3D urban datasets, extracting insights remains challenging due to computational bottlenecks and the complexity of interacting with data. In fact, the intricate geometry of 3D urban environments results in high degrees of occlusion and requires extensive manual viewpoint adjustments that make large-scale exploration inefficient. To address this, we propose a view-based approach for 3D data exploration, where a vector field encodes views from the environment. To support this approach, we introduce a neural field-based method that constructs an efficient implicit representation of 3D environments. This representation enables both faster direct queries, which consist of the computation of view assessment indices, and inverse queries, which help avoid occlusion and facilitate the search for views that match desired data patterns. Our approach supports key urban analysis tasks such as visibility assessments, solar exposure evaluation, and assessing the visual impact of new developments. We validate our method through quantitative experiments, case studies informed by real-world urban challenges, and feedback from domain experts. Results show its effectiveness in finding desirable viewpoints, analyzing building facade visibility, and evaluating views from outdoor spaces. Code and data are publicly available at https://urbantk.org/neural-3d.", "arxiv_id": "2511.14742v1", "url": "http://arxiv.org/abs/2511.14742v1", "published_date": "2025-11-18T18:41:28+00:00", "summary": "The paper presents a neural field-based approach for efficient view computation and data exploration in complex 3D urban environments. By constructing an implicit neural representation of 3D space, the method allows for both direct and inverse querying, facilitating tasks such as visibility analysis and solar exposure evaluation. The approach is validated with quantitative experiments, real-world case studies, and expert feedback, demonstrating improvements in viewpoint selection and urban data analysis.", "tags": ["neural fields", "3D urban environments", "implicit representation", "viewpoint analysis", "computer vision", "data exploration", "AI for urban planning", "occlusion handling"], "questions_answered": ["How can computational bottlenecks in 3D urban data exploration be addressed?", "How can occlusion and manual viewpoint adjustments in urban environments be minimized?", "What methods allow efficient querying and analysis of 3D urban datasets for tasks like visibility and solar exposure?"], "key_findings": ["A neural field-based implicit representation enables efficient direct and inverse queries within complex 3D environments.", "The proposed method supports key urban analysis tasks such as visibility assessment, solar exposure, and visual impact evaluations.", "Experiments and expert feedback validate that the approach improves viewpoint selection and facade visibility analysis in real urban scenarios.", "The method is scalable and publicly available, supporting reproducible research in 3D urban analytics."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:33:44.895634"}, {"type": "paper", "id": "5bdbbc9a8950e1bdfcd4092dd6f2e706", "title": "AdamHD: Decoupled Huber Decay Regularization for Language Model Pre-Training", "authors": ["Fu-Ming Guo", "Yingfang Fan"], "abstract": "Adaptive optimizers with decoupled weight decay, such as AdamW, are the de facto standard for pre-training large transformer-based generative models. Yet the quadratic nature of the $\\ell_2$ penalty embedded in weight decay drives all parameters toward the origin at the same rate, making the update vulnerable to rare but extreme gradient directions and often over-penalizing well-conditioned coordinates. We propose AdamHuberDecay, a drop-in replacement for AdamW that substitutes the $\\ell_2$ penalty with a decoupled smooth Huber regularizer. The resulting update decays parameters quadratically while their magnitude remains below a threshold $\u03b4$, and linearly ($\\ell_1$-like) once they exceed $\u03b4$, yielding (i) bounded regularization gradients, (ii) invariance to per-coordinate second-moment rescaling, and (iii) stronger sparsity pressure on overgrown weights.\n  We derive the closed-form decoupled Huber decay step and show how to integrate it with any Adam-family optimizer at $O(1)$ extra cost. Extensive experiments on GPT-2 and GPT-3 pre-training demonstrate that AdamHuberDecay (a) converges 10-15% faster in wall-clock time, (b) reduces validation perplexity by up to 4 points, (c) delivers performance improvements of 2.5-4.7% across downstream tasks, and (d) yields visibly sparser weight histograms that translate into 20-30% memory savings after magnitude pruning, without tuning the decay coefficient beyond the default grid used for AdamW. Ablations confirm robustness to outlier gradients and large-batch regimes, together with theoretical analyses that bound the expected parameter norm under noisy updates. AdamHuberDecay therefore provides a simple, principled path toward more efficient and resilient training of next-generation foundational generative transformers.", "arxiv_id": "2511.14721v1", "url": "http://arxiv.org/abs/2511.14721v1", "published_date": "2025-11-18T18:08:20+00:00", "summary": "This paper introduces AdamHuberDecay, a drop-in replacement for AdamW in language model pre-training, replacing the traditional $\\ell_2$ weight decay with a decoupled smooth Huber regularizer. AdamHD exhibits advantages such as faster convergence, improved validation perplexity, enhanced downstream performance, and increased sparsity in model weights, leading to significant memory savings without additional hyperparameter tuning.", "tags": ["adaptive optimizers", "regularization", "Huber loss", "weight decay", "transformers", "language model pre-training", "sparsity", "Adam family"], "questions_answered": ["How can regularization in adaptive optimizers be improved to avoid over-penalizing well-conditioned weights?", "Does replacing $\\ell_2$ weight decay with Huber regularization yield better training efficiency and downstream performance?", "Can a new regularization method lead to sparser models and memory savings in large language models?", "Is AdamHuberDecay robust to outlier gradients and suitable for large-batch training regimes?"], "key_findings": ["AdamHuberDecay provides bounded regularization gradients and preserves invariance under per-coordinate rescaling.", "The method leads to 10-15% faster convergence in wall-clock time and up to 4 points lower validation perplexity in transformer pre-training.", "AdamHD delivered 2.5-4.7% improvement in downstream task performance compared to AdamW.", "Adopting Huber decay creates sparser weight distributions and achieves 20-30% memory savings post-magnitude pruning.", "The approach is robust without requiring hyperparameter tuning beyond what is typical for AdamW and is theoretically justified under noisy updates."], "relevancy_score": 9.0, "interesting_score": 9.0, "ingested_at": "2025-11-19T14:33:46.544679"}, {"type": "paper", "id": "e0b2e7518b837fa44ab2ebb0c798e0c3", "title": "Graph Neural Networks for Vehicular Social Networks: Trends, Challenges, and Opportunities", "authors": ["Elham Binshaflout", "Aymen Hamrouni", "Hakim Ghazzai"], "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for modeling complex, interconnected data, making them particularly well suited for a wide range of Intelligent Transportation System (ITS) applications. This survey presents the first comprehensive review dedicated specifically to the use of GNNs within Vehicular Social Networks (VSNs). By leveraging both Euclidean and non-Euclidean transportation-related data, including traffic patterns, road users, and weather conditions, GNNs offer promising solutions for analyzing and enhancing VSN applications. The survey systematically categorizes and analyzes existing studies according to major VSN-related tasks, including traffic flow and trajectory prediction, traffic forecasting, signal control, driving assistance, routing problem, and connectivity management. It further provides quantitative insights and synthesizes key takeaways derived from the literature review. Additionally, the survey examines the available datasets and outlines open research directions needed to advance GNN-based VSN applications. The findings indicate that, although GNNs demonstrate strong potential for improving the accuracy, robustness, and real-time performances of on task-specific or sub-VSN graphs, there remains a notable absence of studies that model a complete, standalone VSN encompassing all functional components. With the increasing availability of data and continued progress in graph learning, GNNs are expected to play a central role in enabling future large-scale and fully integrated VSN applications.", "arxiv_id": "2511.14720v1", "url": "http://arxiv.org/abs/2511.14720v1", "published_date": "2025-11-18T18:07:55+00:00", "summary": "This paper presents a comprehensive survey of Graph Neural Networks (GNNs) in the context of Vehicular Social Networks (VSNs), analyzing their application across various intelligent transportation system (ITS) tasks. It categorizes existing research, highlights datasets, synthesizes key takeaways, and identifies open research challenges for integrating GNNs into large-scale VSNs.", "tags": ["Graph Neural Networks", "Vehicular Social Networks", "Intelligent Transportation Systems", "Traffic Prediction", "Routing", "AI for Transportation", "Graph Learning"], "questions_answered": ["How are GNNs being applied within Vehicular Social Networks?", "What ITS-related tasks benefit from GNN-based approaches in VSNs?", "What are the current datasets and methodologies used in GNN-based VSN research?", "What are the challenges and open research directions for GNN-enabled VSNs?"], "key_findings": ["GNNs show significant potential to improve accuracy, robustness, and real-time performance in various VSN applications including traffic prediction, routing, and connectivity management.", "Most existing studies focus on task-specific or subgraph components of VSNs rather than modeling a fully integrated, standalone VSN.", "There is a lack of comprehensive datasets and end-to-end frameworks for testing GNN approaches across all aspects of VSNs.", "Future advancements in data availability and graph learning techniques are expected to further enable large-scale, fully integrated GNN-based VSN systems."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:33:50.259326"}, {"type": "paper", "id": "0d35f384ebd8dad96117d4ccd8a9533d", "title": "Diffusion As Self-Distillation: End-to-End Latent Diffusion In One Model", "authors": ["Xiyuan Wang", "Muhan Zhang"], "abstract": "Standard Latent Diffusion Models rely on a complex, three-part architecture consisting of a separate encoder, decoder, and diffusion network, which are trained in multiple stages. This modular design is computationally inefficient, leads to suboptimal performance, and prevents the unification of diffusion with the single-network architectures common in vision foundation models. Our goal is to unify these three components into a single, end-to-end trainable network. We first demonstrate that a naive joint training approach fails catastrophically due to ``latent collapse'', where the diffusion training objective interferes with the network's ability to learn a good latent representation. We identify the root causes of this instability by drawing a novel analogy between diffusion and self-distillation based unsupervised learning method. Based on this insight, we propose Diffusion as Self-Distillation (DSD), a new framework with key modifications to the training objective that stabilize the latent space. This approach enables, for the first time, the stable end-to-end training of a single network that simultaneously learns to encode, decode, and perform diffusion. DSD achieves outstanding performance on the ImageNet $256\\times 256$ conditional generation task: FID=13.44/6.38/4.25 with only 42M/118M/205M parameters and 50 training epochs on ImageNet, without using classifier-free-guidance.", "arxiv_id": "2511.14716v1", "url": "http://arxiv.org/abs/2511.14716v1", "published_date": "2025-11-18T17:58:16+00:00", "summary": "This paper proposes Diffusion as Self-Distillation (DSD), a novel framework that unifies the encoder, decoder, and diffusion network of latent diffusion models into a single, end-to-end trainable architecture. By identifying latent collapse as a critical failure mode and introducing self-distillation-inspired modifications to stabilize training, the authors achieve strong ImageNet generation performance with compact models and efficient training.", "tags": ["latent diffusion models", "self-distillation", "end-to-end training", "representation learning", "generative models", "image synthesis"], "questions_answered": ["Can latent diffusion models be unified into a single, end-to-end network?", "Why does naive joint training of encoder, decoder, and diffusion lead to instability?", "How can self-distillation principles stabilize end-to-end learning for diffusion models?"], "key_findings": ["Naively training a unified latent diffusion model causes latent collapse, preventing effective representation learning.", "Framing diffusion as a self-distillation problem reveals the root causes of this collapse.", "The proposed DSD framework introduces a stable training objective allowing end-to-end training and integration of all three components into a single model.", "DSD achieves strong performance on ImageNet generation (FID 13.44/6.38/4.25 for 42M/118M/205M parameters) without classifier-free guidance and requires fewer training epochs."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:33:53.772513"}, {"type": "paper", "id": "f098e8869a56ae2e3c8fcc5496a89c30", "title": "Towards a Unified Analysis of Neural Networks in Nonparametric Instrumental Variable Regression: Optimization and Generalization", "authors": ["Zonghao Chen", "Atsushi Nitanda", "Arthur Gretton", "Taiji Suzuki"], "abstract": "We establish the first global convergence result of neural networks for two stage least squares (2SLS) approach in nonparametric instrumental variable regression (NPIV). This is achieved by adopting a lifted perspective through mean-field Langevin dynamics (MFLD), unlike standard MFLD, however, our setting of 2SLS entails a \\emph{bilevel} optimization problem in the space of probability measures. To address this challenge, we leverage the penalty gradient approach recently developed for bilevel optimization which formulates bilevel optimization as a Lagrangian problem. This leads to a novel fully first-order algorithm, termed \\texttt{F$^2$BMLD}. Apart from the convergence bound, we further provide a generalization bound, revealing an inherent trade-off in the choice of the Lagrange multiplier between optimization and statistical guarantees. Finally, we empirically validate the effectiveness of the proposed method on an offline reinforcement learning benchmark.", "arxiv_id": "2511.14710v1", "url": "http://arxiv.org/abs/2511.14710v1", "published_date": "2025-11-18T17:51:17+00:00", "summary": "This paper provides the first global convergence result for neural networks applied to nonparametric instrumental variable regression (NPIV) using a two-stage least squares (2SLS) approach. It introduces a novel bilevel optimization algorithm (F^2BMLD) leveraging mean-field Langevin dynamics and penalty gradient methods, and demonstrates both theoretical convergence and generalization bounds, with empirical validation on offline RL benchmarks.", "tags": ["Nonparametric Instrumental Variable Regression", "Neural Networks", "Bilevel Optimization", "Mean-field Langevin Dynamics", "Two Stage Least Squares", "Generalization Bounds", "Reinforcement Learning"], "questions_answered": ["How can neural networks be globally optimized in nonparametric instrumental variable regression?", "What algorithmic approach enables convergence and generalization guarantees for neural 2SLS in NPIV?", "How does bilevel optimization via lifted mean-field Langevin dynamics advance NPIV regression?", "What is the trade-off between optimization performance and statistical generalization in this context?"], "key_findings": ["Introduces a lifted mean-field Langevin dynamics approach tailored for bilevel optimization in NPIV neural 2SLS.", "Develops a fully first-order algorithm (F^2BMLD) employing the penalty gradient method for bilevel problems.", "Establishes theoretical convergence and generalization bounds, showing trade-offs controlled by the Lagrange multiplier.", "Empirical results validate the effectiveness of the proposed method on offline reinforcement learning benchmarks."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:33:56.990244"}, {"type": "paper", "id": "5f1dd6fca1ac6b33eff15d171bed6ef4", "title": "Decoupling Urban Food Accessibility Resilience during Disasters through Time-Series Analysis of Human Mobility and Power Outages", "authors": ["Junwei Ma", "Bo Li", "Xiangpeng Li", "Ali Mostafavi"], "abstract": "Disaster-induced power outages create cascading disruptions across urban lifelines, yet the timed coupling between grid failure and essential service access remains poorly quantified. Focusing on Hurricane Beryl in Houston (2024), this study integrates approximately 173000 15-minute outage records with over 1.25 million visits to 3187 food facilities to quantify how infrastructure performance and human access co-evolve. We construct daily indices for outage characteristics (intensity, duration) and food access metrics (redundancy, frequency, proximity), estimate cross-system lags through lagged correlations over zero to seven days, and identify recovery patterns using DTW k-means clustering. Overlaying these clusters yields compound power-access typologies and enables facility-level criticality screening. The analysis reveals a consistent two-day lag: food access reaches its nadir on July 8 at landfall while outage severity peaks around July 10, with negative correlations strongest at a two-day lag and losing significance by day four. We identify four compound typologies from high/low outage crossed with high/low access disruption levels. Road network sparsity, more than income, determines the depth and persistence of access loss. Through this analysis, we enumerate 294 critical food facilities in the study area requiring targeted continuity measures including backup power, microgrids, and feeder prioritization. The novelty lies in measuring interdependency at daily operational resolution while bridging scales from communities to individual facilities, converting dynamic coupling patterns into actionable interventions for phase-sensitive restoration and equity-aware preparedness. The framework is transferable to other lifelines and hazards, offering a generalizable template for diagnosing and mitigating cascading effects on community access during disaster recovery.", "arxiv_id": "2511.14706v1", "url": "http://arxiv.org/abs/2511.14706v1", "published_date": "2025-11-18T17:46:12+00:00", "summary": "This paper investigates the temporal relationship between urban power outages and food accessibility disruptions during Hurricane Beryl in Houston by analyzing large-scale time-series data from outage records and human mobility to food facilities. Using statistical and machine learning methods, it identifies lagged coupling dynamics, clusters recovery typologies, and screens critical facilities for targeted resilience interventions. The framework offers a scalable approach to quantifying and mitigating cascading disaster impacts on access to essential services.", "tags": ["human mobility analysis", "infrastructure interdependency", "time-series clustering", "disaster resilience", "power outage impact", "food access", "dynamic time warping (DTW)", "critical facility screening"], "questions_answered": ["How do disaster-induced power outages temporally affect access to essential urban services like food?", "What are the lagged coupling patterns between infrastructure failure and human mobility to food resources?", "How can time-series analysis and clustering identify critical facilities and inform targeted resilience strategies?", "What structural factors most influence the depth and duration of food access loss during outages?"], "key_findings": ["There is a consistent two-day lag between peak outage severity and the lowest point of food accessibility, with the strongest negative correlation at a two-day lag.", "Recovery from outage and food access disruption can be grouped into four compound typologies via DTW k-means clustering.", "Road network sparsity is a stronger determinant of persistent access loss than socioeconomic factors like income.", "294 critical food facilities were identified for prioritized continuity investments, such as backup power and microgrids.", "The analytical framework provides actionable, phase-sensitive interventions and is transferable to other lifelines and disaster contexts for broader resilience planning."], "relevancy_score": 8.0, "interesting_score": 9.0, "ingested_at": "2025-11-19T14:34:02.002993"}, {"type": "paper", "id": "1861b21fbf37e4924e7fcba583949d98", "title": "Systematic Study on the $\u03b1$-particle preformation factor in the theory of $\u03b1$-decay based on the Tabular Prior-data Fitted Network (TabPFN)", "authors": ["Panpan Qi", "Xuanpeng Xiao", "Gongming Yu", "Haitao Yang", "Qiang Hu"], "abstract": "A hybrid approach combining the Tabular Prior-data Fitted Network (TabPFN) with the Coulomb and Proximity Potential Model (CPPM) is developed to investigate $\u03b1$-particle preformation factors $P_\u03b1$ and their impact on $\u03b1$-decay half-lives. The TabPFN model, trained on 498 nuclei, accurately learns the relationship between the properties of the nuclear structure and $P_\u03b1$, achieving a root mean square deviation of $\u03c3_{\\mathrm{rms}} = 0.211$. The predicted factors reveal clear odd-even staggering and shell closure effects, and exhibit a linear correlation with $Q_\u03b1^{-1/2}$, extending the Geiger-Nuttall systematics. When incorporated into CPPM calculations, the machine learning-based $P_\u03b1$ values significantly improve half-life predictions. The capability of the model is demonstrated through predictions for superheavy nuclei ($Z = 117$--120), suggesting $N = 184$ as a potential neutron magic number.", "arxiv_id": "2511.14705v1", "url": "http://arxiv.org/abs/2511.14705v1", "published_date": "2025-11-18T17:46:02+00:00", "summary": "This paper presents a hybrid approach integrating the Tabular Prior-data Fitted Network (TabPFN), a machine learning model, with the Coulomb and Proximity Potential Model (CPPM) to systematically study alpha-particle preformation factors in alpha-decay. By training on nuclear data, the model enhances predictions of preformation factors and decay half-lives, uncovering structural effects and extending traditional systematics. The approach is validated through improved predictions, including those for superheavy nuclei, highlighting potential new magic numbers.", "tags": ["machine learning applications in nuclear physics", "TabPFN", "alpha-decay modeling", "preformation factor prediction", "Coulomb and Proximity Potential Model", "Geiger-Nuttall law", "superheavy nuclei", "nuclear shell effects"], "questions_answered": ["Can machine learning (specifically TabPFN) accurately predict alpha-particle preformation factors in nuclei?", "Do machine-learned preformation factors improve theoretical predictions of alpha-decay half-lives?", "How do nuclear structure features like odd-even effects and shell closures manifest in data-driven preformation factors?", "Can this approach identify potential magic numbers in superheavy nuclei?"], "key_findings": ["TabPFN, trained on 498 nuclei, can accurately predict alpha-particle preformation factors with low root mean square deviation (\u03c3_rms = 0.211).", "Predicted preformation factors show clear odd-even staggering and shell closure effects, reflecting nuclear structure.", "A linear correlation between preformation factors and Q_\u03b1^{-1/2} is found, extending the Geiger-Nuttall systematics.", "Incorporating ML-based preformation factors into CPPM calculations significantly improves alpha-decay half-life predictions.", "Model predictions for superheavy nuclei suggest N=184 as a possible neutron magic number."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:34:08.209212"}, {"type": "paper", "id": "3f8a14b062b4d9114b350d14ff74866b", "title": "HyMAD: A Hybrid Multi-Activity Detection Approach for Border Surveillance and Monitoring", "authors": ["Sriram Srinivasan", "Srinivasan Aruchamy", "Siva Ram Krisha Vadali"], "abstract": "Seismic sensing has emerged as a promising solution for border surveillance and monitoring; the seismic sensors that are often buried underground are small and cannot be noticed easily, making them difficult for intruders to detect, avoid, or vandalize. This significantly enhances their effectiveness compared to highly visible cameras or fences. However, accurately detecting and distinguishing between overlapping activities that are happening simultaneously, such as human intrusions, animal movements, and vehicle rumbling, remains a major challenge due to the complex and noisy nature of seismic signals. Correctly identifying simultaneous activities is critical because failing to separate them can lead to misclassification, missed detections, and an incomplete understanding of the situation, thereby reducing the reliability of surveillance systems. To tackle this problem, we propose HyMAD (Hybrid Multi-Activity Detection), a deep neural architecture based on spatio-temporal feature fusion. The framework integrates spectral features extracted with SincNet and temporal dependencies modeled by a recurrent neural network (RNN). In addition, HyMAD employs self-attention layers to strengthen intra-modal representations and a cross-modal fusion module to achieve robust multi-label classification of seismic events. e evaluate our approach on a dataset constructed from real-world field recordings collected in the context of border surveillance and monitoring, demonstrating its ability to generalize to complex, simultaneous activity scenarios involving humans, animals, and vehicles. Our method achieves competitive performance and offers a modular framework for extending seismic-based activity recognition in real-world security applications.", "arxiv_id": "2511.14698v1", "url": "http://arxiv.org/abs/2511.14698v1", "published_date": "2025-11-18T17:37:38+00:00", "summary": "This paper introduces HyMAD, a hybrid deep learning framework for robust multi-activity detection using seismic sensors in border surveillance scenarios. HyMAD fuses spatio-temporal features and leverages attention mechanisms to accurately distinguish overlapping seismic events such as humans, animals, and vehicles. Evaluated on real-world data, the approach demonstrates strong performance in complex, simultaneous activity environments.", "tags": ["seismic sensing", "border surveillance", "multi-activity detection", "deep learning", "spatio-temporal feature fusion", "attention mechanisms", "multi-label classification", "SincNet", "RNN"], "questions_answered": ["How can seismic sensors be used for reliable activity detection in border surveillance?", "How can overlapping and simultaneous activities (e.g., humans, animals, vehicles) be accurately detected and distinguished using seismic data?", "Can deep learning models improve the robustness of seismic-based multi-label classification in noisy, real-world scenarios?"], "key_findings": ["Proposes HyMAD, a modular deep neural architecture integrating spectral (SincNet) and temporal (RNN) features for seismic event analysis.", "Introduces self-attention and cross-modal fusion modules to enhance intra-modal representations and achieve robust multi-label classification.", "Demonstrates that HyMAD achieves competitive and generalizable performance on a real-world seismic surveillance dataset, effectively distinguishing simultaneous activities."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:34:13.694816"}, {"type": "paper", "id": "486f47c6dba1a84e0ac157a46aa76b3c", "title": "Marking and re-marking", "authors": ["Matthew Aldridge"], "abstract": "A random number of items each independently marked with one of a collection of colours gives rise to the multinomial marking, which generalises binomial thinning. A multivariate version, where previously marked items are then re-marked, has similar properties to taking a linear transformation of a random vector.", "arxiv_id": "2511.14740v1", "url": "http://arxiv.org/abs/2511.14740v1", "published_date": "2025-11-18T18:35:10+00:00", "summary": "This paper introduces a probabilistic framework where items are randomly marked with one of several colors, described as a multinomial marking process which extends the concept of binomial thinning. It further generalizes to a multivariate case, analyzing the statistical properties when previously marked items are re-marked, drawing parallels to linear transformations in random vectors. The approach provides analytical tools for understanding marking and remarking processes in discrete random systems.", "tags": ["multinomial marking", "probabilistic modeling", "stochastic processes", "discrete random variables", "linear transformation"], "questions_answered": ["How can multinomial marking generalize binomial thinning in random processes?", "What are the statistical properties of systems where items are repeatedly marked and re-marked?", "How does re-marking relate to linear transformations of random vectors?"], "key_findings": ["Multinomial marking serves as a natural extension to binomial thinning, allowing for more than two categories.", "The process of re-marking previously marked items shares similarities with applying linear transformations to multivariate random vectors.", "The theoretical framework developed enables analysis of complex marking and remarking processes in discrete random systems."], "relevancy_score": 4.0, "interesting_score": 6.0, "ingested_at": "2025-11-19T14:34:44.677157"}, {"type": "paper", "id": "fe2ad584616f48d67983d2331c2d1c3c", "title": "\\textit{FLARE}: Adaptive Multi-Dimensional Reputation for Robust Client Reliability in Federated Learning", "authors": ["Abolfazl Younesi", "Leon Kiss", "Zahra Najafabadi Samani", "Juan Aznar Poveda", "Thomas Fahringer"], "abstract": "Federated learning (FL) enables collaborative model training while preserving data privacy. However, it remains vulnerable to malicious clients who compromise model integrity through Byzantine attacks, data poisoning, or adaptive adversarial behaviors. Existing defense mechanisms rely on static thresholds and binary classification, failing to adapt to evolving client behaviors in real-world deployments. We propose FLARE, an adaptive reputation-based framework that transforms client reliability assessment from binary decisions to a continuous, multi-dimensional trust evaluation. FLARE integrates: (i) a multi-dimensional reputation score capturing performance consistency, statistical anomaly indicators, and temporal behavior, (ii) a self-calibrating adaptive threshold mechanism that adjusts security strictness based on model convergence and recent attack intensity, (iii) reputation-weighted aggregation with soft exclusion to proportionally limit suspicious contributions rather than eliminating clients outright, and (iv) a Local Differential Privacy (LDP) mechanism enabling reputation scoring on privatized client updates. We further introduce a highly evasive Statistical Mimicry (SM) attack, a benchmark adversary that blends honest gradients with synthetic perturbations and persistent drift to remain undetected by traditional filters. Extensive experiments with 100 clients on MNIST, CIFAR-10, and SVHN demonstrate that FLARE maintains high model accuracy and converges faster than state-of-the-art Byzantine-robust methods under diverse attack types, including label flipping, gradient scaling, adaptive attacks, ALIE, and SM. FLARE improves robustness by up to 16% and preserves model convergence within 30% of the non-attacked baseline, while achieving strong malicious-client detection performance with minimal computational overhead. https://github.com/Anonymous0-0paper/FLARE", "arxiv_id": "2511.14715v1", "url": "http://arxiv.org/abs/2511.14715v1", "published_date": "2025-11-18T17:57:40+00:00", "summary": "FLARE introduces an adaptive, multi-dimensional reputation framework to robustly assess and mitigate unreliable clients in federated learning. By moving beyond binary trust decisions, FLARE leverages dynamic scoring, privacy-preserving updates, and soft exclusion to defend against a broad range of sophisticated attacks. Experimental results demonstrate improved robustness and faster convergence compared to existing Byzantine-robust methods.", "tags": ["Federated Learning", "Reputation Systems", "Byzantine Robustness", "Adaptive Defense Mechanisms", "Differential Privacy", "Statistical Attacks", "Robust Aggregation", "Adversarial ML"], "questions_answered": ["How can federated learning systems more effectively identify and limit the impact of malicious clients?", "What mechanisms can adaptively track and respond to evolving adversarial behaviors in real-world client populations?", "Can reputation-based, continuous client assessment improve robustness and convergence beyond binary filtering methods?", "How can reputation scoring be performed when client updates are privacy-preserved?"], "key_findings": ["A multi-dimensional reputation score (combining performance, statistical anomaly, and temporal patterns) can better capture client reliability.", "FLARE's adaptive thresholding tunes the security level based on model convergence and attack intensity, outperforming static defenses.", "Reputation-weighted, soft exclusion aggregation outperforms binary exclusion, maintaining accuracy and model stability.", "The proposed Local Differential Privacy integration allows for effective reputation scoring while preserving client-side privacy.", "Statistical Mimicry (SM) attack serves as a new benchmark for evasion, and FLARE demonstrates resilience against SM and other advanced attacks.", "FLARE achieves up to 16% greater robustness and maintains convergence within 30% of clean baseline under diverse attack scenarios."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:34:47.843166"}, {"type": "paper", "id": "76e746471f85e87b9dd6bce6c2195f50", "title": "FreeSwim: Revisiting Sliding-Window Attention Mechanisms for Training-Free Ultra-High-Resolution Video Generation", "authors": ["Yunfeng Wu", "Jiayi Song", "Zhenxiong Tan", "Zihao He", "Songhua Liu"], "abstract": "The quadratic time and memory complexity of the attention mechanism in modern Transformer based video generators makes end-to-end training for ultra high resolution videos prohibitively expensive. Motivated by this limitation, we introduce a training-free approach that leverages video Diffusion Transformers pretrained at their native scale to synthesize higher resolution videos without any additional training or adaptation. At the core of our method lies an inward sliding window attention mechanism, which originates from a key observation: maintaining each query token's training scale receptive field is crucial for preserving visual fidelity and detail. However, naive local window attention, unfortunately, often leads to repetitive content and exhibits a lack of global coherence in the generated results. To overcome this challenge, we devise a dual-path pipeline that backs up window attention with a novel cross-attention override strategy, enabling the semantic content produced by local attention to be guided by another branch with a full receptive field and, therefore, ensuring holistic consistency. Furthermore, to improve efficiency, we incorporate a cross-attention caching strategy for this branch to avoid the frequent computation of full 3D attention. Extensive experiments demonstrate that our method delivers ultra-high-resolution videos with fine-grained visual details and high efficiency in a training-free paradigm. Meanwhile, it achieves superior performance on VBench, even compared to training-based alternatives, with competitive or improved efficiency. Codes are available at: https://github.com/WillWu111/FreeSwim", "arxiv_id": "2511.14712v1", "url": "http://arxiv.org/abs/2511.14712v1", "published_date": "2025-11-18T17:56:04+00:00", "summary": "This paper introduces FreeSwim, a training-free method for generating ultra-high-resolution videos using pretrained video Diffusion Transformers. By leveraging an inward sliding window attention mechanism complemented with a novel cross-attention override and caching strategies, FreeSwim achieves enhanced efficiency and visual fidelity without additional training. Experimental results show superior performance compared to existing training-based alternatives on standard video benchmarks.", "tags": ["sliding-window attention", "video generation", "Diffusion Transformers", "ultra-high-resolution", "training-free methods", "cross-attention", "efficient inference"], "questions_answered": ["How can ultra-high-resolution video generation be efficiently achieved with pretrained video Transformers, without additional training?", "How can local and global coherence be maintained in high-resolution video synthesis using sliding-window attention?", "What strategies can mitigate the computational cost of attention mechanisms in Transformers for large-scale video generation?"], "key_findings": ["An inward sliding window attention mechanism preserves the receptive field for each query token, maintaining high visual fidelity.", "Naive local window attention can lead to repetitive content and a lack of global coherence, which is addressed by a dual-path pipeline involving a cross-attention override.", "Cross-attention caching allows the method to avoid frequent full 3D attention computations, significantly improving efficiency.", "FreeSwim generates ultra-high-resolution videos in a training-free manner, outperforming many training-based approaches on VBench in both quality and efficiency."], "relevancy_score": 9.0, "interesting_score": 9.0, "ingested_at": "2025-11-19T14:34:50.947284"}, {"type": "paper", "id": "04c46f753be63c9c836a138e16d066fd", "title": "Strategic Innovation Management in the Age of Large Language Models Market Intelligence, Adaptive R&D, and Ethical Governance", "authors": ["Raha Aghaei", "Ali A. Kiaei", "Mahnaz Boush", "Mahan Rofoosheh", "Mohammad Zavvar"], "abstract": "This study analyzes the multiple functions of Large Language Models (LLMs) in transforming research and development (R&D) processes. By automating knowledge discovery, boosting hypothesis creation, integrating transdisciplinary insights, and enabling cooperation within innovation ecosystems, LLMs dramatically improve the efficiency and effectiveness of research processes. Through extensive analysis of scientific literature, patent databases, and experimental data, these models enable more flexible and informed R&D workflows, ultimately accelerating innovation cycles and lowering time-to-market for breakthrough ideas.", "arxiv_id": "2511.14709v1", "url": "http://arxiv.org/abs/2511.14709v1", "published_date": "2025-11-18T17:50:39+00:00", "summary": "This paper examines how Large Language Models (LLMs) are transforming R&D management by automating knowledge discovery, generating hypotheses, and fostering interdisciplinary collaboration. It highlights the role of LLMs in enhancing market intelligence, accelerating innovation cycles, and ensuring agile and ethical governance in innovation processes.", "tags": ["Large Language Models", "R&D Automation", "Market Intelligence", "Adaptive Research", "Innovation Management", "Ethical AI", "Transdisciplinary Collaboration"], "questions_answered": ["How can LLMs improve research and development processes?", "What role do LLMs play in market intelligence and adaptive R&D workflows?", "How do LLMs promote ethical governance and cooperation within innovation ecosystems?"], "key_findings": ["LLMs automate complex knowledge discovery and hypothesis generation, increasing R&D efficiency.", "Integration of multidisciplinary insights through LLMs leads to more flexible and informed research workflows.", "LLMs accelerate the innovation cycle and reduce time-to-market for novel ideas.", "LLMs facilitate ethical governance and cooperation within complex innovation ecosystems."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:34:53.270339"}, {"type": "paper", "id": "34d89088e3d80a765c2412c826cd763f", "title": "Systematic Study of the Self-Renormalized Nucleon Gluon PDF in Large-Momentum Effective Theory", "authors": ["Alex NieMiera", "William Good", "Huey-Wen Lin", "Fei Yao"], "abstract": "We present a systematic study of the nucleon gluon parton distribution function (PDF) using the self-renormalized large-momentum effective theory (LaMET) approach in lattice QCD. This work extends previous gluon-PDF extractions by performing a detailed analysis of key systematic effects, including gauge-link smearing, lattice spacing, pion mass, and nucleon boost momentum. The self-renormalization framework mitigates ultraviolet divergences associated with Wilson-line self-energy and renormalon contributions by combining lattice matrix elements with perturbative short-distance information, thereby preserving the correct infrared structure. Calculations are performed on $N_f=2+1+1$ HISQ ensembles generated by the MILC Collaboration at three lattice spacings and two pion masses, with boosted nucleon states reaching momenta up to 2.2~GeV. We determine renormalization factors from zero-momentum matrix elements and apply hybrid renormalization to suppress discretization artifacts. After extrapolating large-separation behavior and performing Fourier transforms, we reconstruct quasi-PDFs and match them to lightcone PDFs using next-to-leading order Wilson coefficients. Our results demonstrate that smearing and lattice-spacing effects are under control, and pion-mass and lattice-spacing dependence is mild relative to the current $O(10^6)$ statistics; however, momentum dependence remains a significant source of uncertainty. Future work including even larger boost momenta will be essential to reduce systematics in lattice determinations of the gluon PDF and to advance toward precision QCD phenomenology at the LHC and the future Electron-Ion Collider.", "arxiv_id": "2511.14708v1", "url": "http://arxiv.org/abs/2511.14708v1", "published_date": "2025-11-18T17:50:07+00:00", "summary": "This paper presents a systematic lattice QCD study of the nucleon gluon parton distribution function (PDF) using the self-renormalized large-momentum effective theory (LaMET) approach. The authors analyze key systematic effects such as gauge-link smearing, lattice spacing, pion mass, and nucleon boost momentum, applying hybrid renormalization to improve results. Their findings show controlled systematics except for momentum dependence, with implications for future precision gluon PDF determinations relevant to LHC and EIC experiments.", "tags": ["Lattice QCD", "Gluon PDF", "Large-Momentum Effective Theory", "Self-Renormalization", "Systematics Analysis", "Hybrid Renormalization", "High-energy Physics"], "questions_answered": ["How can the nucleon gluon parton distribution function be systematically extracted using lattice QCD and LaMET?", "What are the impacts of gauge-link smearing, lattice spacing, pion mass, and boost momentum on gluon PDF extractions?", "How does self-renormalization mitigate ultraviolet divergences in lattice PDF calculations?"], "key_findings": ["Self-renormalization effectively suppresses ultraviolet divergences and preserves infrared structure in gluon PDF calculations.", "Systematics from smearing, lattice spacing, and pion mass are well controlled relative to statistical uncertainties.", "Momentum dependence introduces the largest uncertainty in the determination of gluon PDFs and needs further study with higher boost states.", "Hybrid renormalization improves the suppression of discretization artifacts in the results."], "relevancy_score": 4.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:34:55.758614"}, {"type": "paper", "id": "542391d4faa23a0510b54dfd16ec888c", "title": "Near-Lossless Model Compression Enables Longer Context Inference in DNA Large Language Models", "authors": ["Rui Zhu", "Xiaopu Zhou", "Haixu Tang", "Stephen W. Scherer", "Lucila Ohno-Machado"], "abstract": "Trained on massive cross-species DNA corpora, DNA large language models (LLMs) learn the fundamental \"grammar\" and evolutionary patterns of genomic sequences. This makes them powerful priors for DNA sequence modeling, particularly over long ranges. However, two major constraints hinder their use in practice: the quadratic computational cost of self-attention and the growing memory required for key-value (KV) caches during autoregressive decoding. These constraints force the use of heuristics such as fixed-window truncation or sliding windows, which compromise fidelity on ultra-long sequences by discarding distant information. We introduce FOCUS (Feature-Oriented Compression for Ultra-long Self-attention), a progressive context-compression module that can be plugged into pretrained DNA LLMs. FOCUS combines the established k-mer representation in genomics with learnable hierarchical compression: it inserts summary tokens at k-mer granularity and progressively compresses attention key and value activations across multiple Transformer layers, retaining only the summary KV states across windows while discarding ordinary-token KV. A shared-boundary windowing scheme yields a stationary cross-window interface that propagates long-range information with minimal loss. We validate FOCUS on an Evo-2-based DNA LLM fine-tuned on GRCh38 chromosome 1 with self-supervised training and randomized compression schedules to promote robustness across compression ratios. On held-out human chromosomes, FOCUS achieves near-lossless fidelity: compressing a 1 kb context into only 10 summary tokens (about 100x) shifts the average per-nucleotide probability by only about 0.0004. Compared to a baseline without compression, FOCUS reduces KV-cache memory and converts effective inference scaling from O(N^2) to near-linear O(N), enabling about 100x longer inference windows on commodity GPUs with near-lossless fidelity.", "arxiv_id": "2511.14694v1", "url": "http://arxiv.org/abs/2511.14694v1", "published_date": "2025-11-18T17:29:39+00:00", "summary": "This paper introduces FOCUS, a progressive context-compression module for DNA large language models (LLMs) that enables efficient and near-lossless long-context inference. By combining k-mer representations, hierarchical compression, and a shared-boundary windowing scheme, FOCUS drastically reduces memory and computational requirements, allowing LLMs to maintain high fidelity over much longer DNA sequences.", "tags": ["DNA large language models", "model compression", "long-context inference", "transformer efficiency", "attention mechanism", "genomics", "key-value cache", "k-mer representation"], "questions_answered": ["How can the quadratic cost and memory requirements of attention mechanisms in DNA LLMs be mitigated?", "Can model compression enable long-context inference in DNA sequence modeling with minimal fidelity loss?", "How can distant information in ultra-long genomic sequences be preserved efficiently during autoregressive inference?"], "key_findings": ["FOCUS introduces a context-compression approach that combines k-mer-based summary tokens and learnable hierarchical compression within DNA LLMs.", "By retaining only the summary key-value states across windows, FOCUS achieves up to 100x context compression with near-lossless accuracy (probability shift ~0.0004 per nucleotide).", "Inference scalability improves from O(N^2) to near-linear O(N), substantially reducing KV-cache memory usage and enabling much longer context windows on standard GPUs compared to uncompressed baselines."], "relevancy_score": 9.0, "interesting_score": 9.0, "ingested_at": "2025-11-19T14:34:59.812586"}, {"type": "paper", "id": "237fcd23a294c814d8cfd07a0d5203fa", "title": "LAUD: Integrating Large Language Models with Active Learning for Unlabeled Data", "authors": ["Tzu-Hsuan Chou", "Chun-Nan Chou"], "abstract": "Large language models (LLMs) have shown a remarkable ability to generalize beyond their pre-training data, and fine-tuning LLMs can elevate performance to human-level and beyond. However, in real-world scenarios, lacking labeled data often prevents practitioners from obtaining well-performing models, thereby forcing practitioners to highly rely on prompt-based approaches that are often tedious, inefficient, and driven by trial and error. To alleviate this issue of lacking labeled data, we present a learning framework integrating LLMs with active learning for unlabeled dataset (LAUD). LAUD mitigates the cold-start problem by constructing an initial label set with zero-shot learning. Experimental results show that LLMs derived from LAUD outperform LLMs with zero-shot or few-shot learning on commodity name classification tasks, demonstrating the effectiveness of LAUD.", "arxiv_id": "2511.14738v1", "url": "http://arxiv.org/abs/2511.14738v1", "published_date": "2025-11-18T18:31:00+00:00", "summary": "This paper introduces LAUD, a framework that integrates large language models (LLMs) with active learning to address the challenge of training on unlabeled data. LAUD uses zero-shot learning to generate an initial labeled set and iteratively improves the model's performance, outperforming standard zero-shot and few-shot approaches in commodity name classification tasks.", "tags": ["Large Language Models", "Active Learning", "Zero-shot Learning", "Unlabeled Data", "Data Labeling", "Text Classification"], "questions_answered": ["How can practitioners train effective LLMs when labeled data is scarce or unavailable?", "Can integrating active learning overcome the cold-start problem in LLM adaptation?", "Does zero-shot labeling provide a useful starting point for active learning with LLMs?"], "key_findings": ["LAUD provides a novel framework that mitigates the cold-start problem by leveraging zero-shot learning to generate an initial labeled set.", "Integrating LLMs with active learning yields better performance on commodity name classification than pure zero-shot or few-shot learning setups.", "LAUD enables more efficient and less tedious model improvement in scenarios with limited labeled data."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:35:31.127554"}, {"type": "paper", "id": "f463a22af713a6c2bbc3fe25a594fa84", "title": "When AI Democratizes Exploitation: LLM-Assisted Strategic Manipulation of Fair Division Algorithms", "authors": ["Priyanka Verma", "Balagopal Unnikrishnan"], "abstract": "Fair resource division algorithms, like those implemented in Spliddit platform, have traditionally been considered difficult for the end users to manipulate due to its complexities. This paper demonstrates how Large Language Models (LLMs) can dismantle these protective barriers by democratizing access to strategic expertise. Through empirical analysis of rent division scenarios on Spliddit algorithms, we show that users can obtain actionable manipulation strategies via simple conversational queries to AI assistants. We present four distinct manipulation scenarios: exclusionary collusion where majorities exploit minorities, defensive counterstrategies that backfire, benevolent subsidization of specific participants, and cost minimization coalitions. Our experiments reveal that LLMs can explain algorithmic mechanics, identify profitable deviations, and generate specific numerical inputs for coordinated preference misreporting--capabilities previously requiring deep technical knowledge. These findings extend algorithmic collective action theory from classification contexts to resource allocation scenarios, where coordinated preference manipulation replaces feature manipulation. The implications reach beyond rent division to any domain using algorithmic fairness mechanisms for resource division. While AI-enabled manipulation poses risks to system integrity, it also creates opportunities for preferential treatment of equity deserving groups. We argue that effective responses must combine algorithmic robustness, participatory design, and equitable access to AI capabilities, acknowledging that strategic sophistication is no longer a scarce resource.", "arxiv_id": "2511.14722v1", "url": "http://arxiv.org/abs/2511.14722v1", "published_date": "2025-11-18T18:09:02+00:00", "summary": "This paper investigates how Large Language Models (LLMs) enable ordinary users to exploit fair division algorithms, such as those in the Spliddit platform, by providing easy access to manipulation strategies that previously required expert knowledge. Through empirical rent division experiments, the authors demonstrate that conversational AI can facilitate various types of strategic manipulations, challenging the assumed integrity of algorithmic fairness systems and highlighting new risks and opportunities for collective action.", "tags": ["AI-assisted manipulation", "LLM applications", "algorithmic fairness", "resource allocation", "collective action", "fair division", "preference misreporting", "strategic behavior"], "questions_answered": ["How can LLMs make it easier for non-experts to manipulate fair division algorithms?", "What types of strategic manipulations can be achieved using conversational AI in resource allocation contexts?", "What are the implications of democratizing strategic knowledge for the integrity and design of fair division systems?"], "key_findings": ["LLMs allow users to easily understand and exploit the mechanics of fair division algorithms via natural language queries.", "AI-powered guidance enables a variety of manipulative strategies, including collusion, defensive tactics, benevolent subsidy coordination, and cost minimization.", "Manipulation strategies that previously required significant technical expertise are now accessible to any user, threatening the robustness of fairness-driven systems.", "The risks and benefits of AI-enabled manipulation extend beyond rent division to any resource allocation setting employing algorithmic fairness.", "Effective responses should integrate algorithmic robustness with inclusive AI access and participatory design to maintain system equity."], "relevancy_score": 9.0, "interesting_score": 9.0, "ingested_at": "2025-11-19T14:35:35.282452"}, {"type": "paper", "id": "37c299f67f1a4f3348798e841ce6c5b8", "title": "Natural Language Interfaces for Databases: What Do Users Think?", "authors": ["Panos Ipeirotis", "Haotian Zheng"], "abstract": "Natural Language Interfaces for Databases (NLIDBs) aim to make database querying accessible by allowing users to ask questions in everyday language rather than using formal SQL queries. Despite significant advancements in translation accuracy, critical usability challenges, such as user frustration, query refinement strategies, and error recovery, remain underexplored. To investigate these usability dimensions, we conducted a mixed-method user study comparing SQL-LLM, a state-of-the-art NL2SQL system, with Snowflake, a traditional SQL analytics platform. Our controlled evaluation involved 20 participants completing realistic database querying tasks across 12 queries each. Results show that SQL-LLM significantly reduced query completion times by 10 to 30 percent (mean: 418 s vs. 629 s, p = 0.036) and improved overall accuracy from 50 to 75 percent (p = 0.002). Additionally, participants using SQL-LLM exhibited fewer query reformulations, recovered from errors 30 to 40 seconds faster, and reported lower frustration levels compared to Snowflake users. Behavioral analysis revealed that SQL-LLM encouraged structured, schema-first querying strategies, enhancing user confidence and efficiency, particularly for complex queries. These findings underscore the practical significance of well-designed, user-friendly NLIDBs in business analytics settings, emphasizing the critical role of usability alongside technical accuracy in real-world deployments.", "arxiv_id": "2511.14718v1", "url": "http://arxiv.org/abs/2511.14718v1", "published_date": "2025-11-18T18:04:24+00:00", "summary": "This paper investigates the usability of Natural Language Interfaces for Databases (NLIDBs) by comparing a state-of-the-art NL2SQL system (SQL-LLM) with a traditional SQL platform (Snowflake) through a controlled user study. The study finds that SQL-LLM significantly improves query efficiency, accuracy, and user satisfaction, highlighting the importance of usability in addition to translation accuracy for real-world analytics tasks.", "tags": ["Natural Language Interfaces", "NLIDB", "NL2SQL", "User Study", "Database Usability", "Large Language Models", "Human-Computer Interaction", "Business Analytics"], "questions_answered": ["How do users perceive and interact with Natural Language Interfaces for Databases compared to traditional SQL interfaces?", "What usability challenges do users face when using NLIDBs, such as frustration, error recovery, and query refinement?", "Does a state-of-the-art NL2SQL system improve efficiency, accuracy, and user experience in real-world analytics tasks?"], "key_findings": ["SQL-LLM reduced query completion times by 10-30% and improved accuracy from 50% to 75% compared to a traditional SQL platform.", "Users made fewer query reformulations and recovered from errors significantly faster when using SQL-LLM.", "Participants reported lower frustration and greater confidence with SQL-LLM, especially for complex queries.", "SQL-LLM encouraged more structured, schema-first querying strategies among users.", "Usability is as critical as translation accuracy for the practical adoption and effectiveness of NLIDBs in business analytics."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:35:38.178558"}, {"type": "paper", "id": "4b601a9835ec22dac37da394c06cd334", "title": "Attention via Synaptic Plasticity is All You Need: A Biologically Inspired Spiking Neuromorphic Transformer", "authors": ["Kallol Mondal", "Ankush Kumar"], "abstract": "Attention is the brain's ability to selectively focus on a few specific aspects while ignoring irrelevant ones. This biological principle inspired the attention mechanism in modern Transformers. Transformers now underpin large language models (LLMs) such as GPT, but at the cost of massive training and inference energy, leading to a large carbon footprint. While brain attention emerges from neural circuits, Transformer attention relies on dot-product similarity to weight elements in the input sequence. Neuromorphic computing, especially spiking neural networks (SNNs), offers a brain-inspired path to energy-efficient intelligence. Despite recent work on attention-based spiking Transformers, the core attention layer remains non-neuromorphic. Current spiking attention (i) relies on dot-product or element-wise similarity suited to floating-point operations, not event-driven spikes; (ii) keeps attention matrices that suffer from the von Neumann bottleneck, limiting in-memory computing; and (iii) still diverges from brain-like computation. To address these issues, we propose the Spiking STDP Transformer (S$^{2}$TDPT), a neuromorphic Transformer that implements self-attention through spike-timing-dependent plasticity (STDP), embedding query--key correlations in synaptic weights. STDP, a core mechanism of memory and learning in the brain and widely studied in neuromorphic devices, naturally enables in-memory computing and supports non-von Neumann hardware. On CIFAR-10 and CIFAR-100, our model achieves 94.35\\% and 78.08\\% accuracy with only four timesteps and 0.49 mJ on CIFAR-100, an 88.47\\% energy reduction compared to a standard ANN Transformer. Grad-CAM shows that the model attends to semantically relevant regions, enhancing interpretability. Overall, S$^{2}$TDPT illustrates how biologically inspired attention can yield energy-efficient, hardware-friendly, and explainable neuromorphic models.", "arxiv_id": "2511.14691v1", "url": "http://arxiv.org/abs/2511.14691v1", "published_date": "2025-11-18T17:28:29+00:00", "summary": "This paper introduces the Spiking STDP Transformer (S$^{2}$TDPT), a neuromorphic Transformer architecture that replaces traditional dot-product attention with spike-timing-dependent plasticity (STDP), enabling a biologically plausible, energy-efficient attention mechanism for spiking neural networks. The model achieves competitive accuracy on CIFAR-10 and CIFAR-100 datasets while massively reducing inference energy consumption. The approach also enhances interpretability through biologically inspired mechanisms and supports hardware-friendly, non-von Neumann computations.", "tags": ["neuromorphic computing", "spiking neural networks", "transformers", "attention mechanisms", "spike-timing-dependent plasticity", "energy efficiency", "explainable AI"], "questions_answered": ["How can attention mechanisms in Transformers be made more biologically plausible and energy-efficient?", "Can spike-timing-dependent plasticity (STDP) replace dot-product attention in neuromorphic networks?", "Does a neuromorphic attention mechanism enable hardware-friendly, in-memory computing?", "How does the use of STDP-based attention affect model interpretability and performance?"], "key_findings": ["The proposed S$^{2}$TDPT replaces dot-product attention with STDP-based mechanisms, embedding attention dynamics in synaptic weights.", "The model achieves 94.35% accuracy on CIFAR-10 and 78.08% on CIFAR-100 with only four timesteps, demonstrating competitive performance.", "Energy consumption is reduced by 88.47% compared to a standard ANN Transformer, requiring only 0.49 mJ on CIFAR-100.", "The approach naturally supports in-memory computing and non-von Neumann architectures, making it suitable for neuromorphic hardware.", "Interpretability is improved, as evidenced by Grad-CAM visualizations showing the model attends to semantically relevant regions."], "relevancy_score": 9.0, "interesting_score": 9.0, "ingested_at": "2025-11-19T14:35:42.845984"}, {"type": "paper", "id": "22b133a2647455898123ad48e5c22bbf", "title": "Ground Truth Generation for Multilingual Historical NLP using LLMs", "authors": ["Clovis Gladstone", "Zhao Fang", "Spencer Dean Stewart"], "abstract": "Historical and low-resource NLP remains challenging due to limited annotated data and domain mismatches with modern, web-sourced corpora. This paper outlines our work in using large language models (LLMs) to create ground-truth annotations for historical French (16th-20th centuries) and Chinese (1900-1950) texts. By leveraging LLM-generated ground truth on a subset of our corpus, we were able to fine-tune spaCy to achieve significant gains on period-specific tests for part-of-speech (POS) annotations, lemmatization, and named entity recognition (NER). Our results underscore the importance of domain-specific models and demonstrate that even relatively limited amounts of synthetic data can improve NLP tools for under-resourced corpora in computational humanities research.", "arxiv_id": "2511.14688v1", "url": "http://arxiv.org/abs/2511.14688v1", "published_date": "2025-11-18T17:25:43+00:00", "summary": "This paper explores the use of large language models (LLMs) to automatically generate ground-truth annotations for historical French and Chinese texts. Using LLM-created synthetic data to fine-tune spaCy, the authors report significant performance improvements in period-specific part-of-speech tagging, lemmatization, and named entity recognition for historically under-resourced corpora. The results highlight synthetic data's utility for improving NLP in computational humanities.", "tags": ["historical NLP", "large language models", "synthetic data generation", "multilingual corpora", "low-resource languages", "POS tagging", "named entity recognition", "lemmatization", "fine-tuning", "computational humanities"], "questions_answered": ["How can annotated data be generated for low-resource and historical languages?", "Can synthetic ground-truth data produced by LLMs improve the performance of NLP models on historical texts?", "What impact does domain-specific fine-tuning have on traditional NLP tasks in under-resourced corpora?"], "key_findings": ["LLMs can effectively generate ground-truth annotations for historical texts in both French and Chinese.", "Fine-tuning spaCy on LLM-generated synthetic data leads to significant improvements in POS tagging, lemmatization, and NER for period-specific tests.", "Relatively small amounts of synthetic data can yield notable gains for under-resourced, domain-specific NLP applications."], "relevancy_score": 8.0, "interesting_score": 7.0, "ingested_at": "2025-11-19T14:35:46.907621"}, {"type": "paper", "id": "d4f65a9a5b77ca44820ee022e2023763", "title": "Encoding and Understanding Astrophysical Information in Large Language Model-Generated Summaries", "authors": ["Kiera McCormick", "Rafael Mart\u00ednez-Galarza"], "abstract": "Large Language Models have demonstrated the ability to generalize well at many levels across domains, modalities, and even shown in-context learning capabilities. This enables research questions regarding how they can be used to encode physical information that is usually only available from scientific measurements, and loosely encoded in textual descriptions. Using astrophysics as a test bed, we investigate if LLM embeddings can codify physical summary statistics that are obtained from scientific measurements through two main questions: 1) Does prompting play a role on how those quantities are codified by the LLM? and 2) What aspects of language are most important in encoding the physics represented by the measurement? We investigate this using sparse autoencoders that extract interpretable features from the text.", "arxiv_id": "2511.14685v1", "url": "http://arxiv.org/abs/2511.14685v1", "published_date": "2025-11-18T17:23:29+00:00", "summary": "This paper explores how Large Language Model (LLM) embeddings can encode astrophysical information typically derived from scientific measurements, by analyzing text-based summaries. Using sparse autoencoders for feature extraction, the authors investigate the impact of prompting and linguistic aspects on how LLMs represent physical quantities in text.", "tags": ["Large Language Models", "Astrophysics", "Text Summarization", "Embeddings", "Sparse Autoencoders", "Scientific Measurements", "Prompt Engineering"], "questions_answered": ["Does the manner of prompting affect how LLMs encode scientific measurement-derived quantities?", "Which aspects of language most influence the encoding of physical information in LLM-generated summaries?"], "key_findings": ["Prompting significantly influences how LLM embeddings codify physical summary statistics derived from measurements.", "Linguistic features in summaries play a key role in how physics-related information is encoded by LLMs.", "Sparse autoencoders can be used to extract interpretable features from LLM-generated text that relate to underlying scientific quantities."], "relevancy_score": 8.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:35:50.301291"}, {"type": "paper", "id": "e7f9c14975fca515fb63d545caf77efb", "title": "SMRC: Aligning Large Language Models with Student Reasoning for Mathematical Error Correction", "authors": ["Biaojie Zeng", "Min Zhang", "Juan Zhou", "Fengrui Liu", "Ruiyang Huang", "Xin Lin"], "abstract": "Large language models (LLMs) often make reasoning errors when solving mathematical problems, and how to automatically detect and correct these errors has become an important research direction. However, existing approaches \\textit{mainly focus on self-correction within the model}, which falls short of the ``teacher-style`` correction required in educational settings, \\textit{i.e.}, systematically guiding and revising a student's problem-solving process. To address this gap, we propose \\texttt{SMRC} (\\textit{\\underline{S}tudent \\underline{M}athematical \\underline{R}easoning \\underline{C}orrection}), a novel method that aligns LLMs with student reasoning. Specifically, \\texttt{SMRC} formulates student reasoning as a multi-step sequential decision problem and introduces Monte Carlo Tree Search (MCTS) to explore optimal correction paths. To reduce the cost of the annotating process-level rewards, we leverage breadth-first search (BFS) guided by LLMs and final-answer evaluation to generate reward signals, which are then distributed across intermediate reasoning steps via a back-propagation mechanism, enabling fine-grained process supervision. Additionally, we construct a benchmark for high school mathematics, MSEB (Multi-Solution Error Benchmark), consisting of 158 instances that include problem statements, student solutions, and correct reasoning steps. We further propose a dual evaluation protocol centered on \\textbf{solution accuracy} and \\textbf{correct-step retention}, offering a comprehensive measure of educational applicability. Experiments demonstrate that \\texttt{SMRC} significantly outperforms existing methods on two public datasets (ProcessBench and MR-GSM8K) and our MSEB in terms of effectiveness and overall performance. The code and data are available at https://github.com/Mind-Lab-ECNU/SMRC.", "arxiv_id": "2511.14684v1", "url": "http://arxiv.org/abs/2511.14684v1", "published_date": "2025-11-18T17:22:37+00:00", "summary": "The paper introduces SMRC, a novel method for aligning large language models (LLMs) with student reasoning to automatically detect and systematically correct mathematical reasoning errors in educational settings. By formulating the correction process as a multi-step decision problem and utilizing Monte Carlo Tree Search (MCTS), the method enables fine-grained process supervision using efficiently generated reward signals. SMRC demonstrates superior performance over existing techniques on multiple public benchmarks and a newly created high school mathematics error correction dataset.", "tags": ["large language models", "mathematical reasoning", "educational AI", "error correction", "Monte Carlo Tree Search", "process supervision", "benchmarking"], "questions_answered": ["How can large language models be aligned with student reasoning for mathematical error correction?", "What methods can systematically guide and revise a student's problem-solving process in mathematics using AI?", "How can reward signals be efficiently generated and distributed for supervising multi-step reasoning in LLMs?", "Is it possible to benchmark and evaluate error correction capabilities in educational mathematics AI systems?"], "key_findings": ["SMRC frames student mathematical error correction as a multi-step sequential decision problem using MCTS.", "A new method for generating dense, process-level reward signals using BFS, LLM guidance, and back-propagation enables finer supervision without high annotation costs.", "The Multi-Solution Error Benchmark (MSEB) is introduced for evaluating mathematical error correction with a dual focus on solution accuracy and correct-step retention.", "SMRC outperforms prior state-of-the-art approaches on public datasets and the new benchmark in both effectiveness and educational applicability."], "relevancy_score": 9.0, "interesting_score": 8.0, "ingested_at": "2025-11-19T14:35:53.907430"}, {"type": "paper", "id": "fa183fb3fce9d950e17e899feffd928f", "title": "A weak convergence approach to the large deviations of the dynamic Schr\u00f6dinger problem", "authors": ["Viktor Nilsson", "Pierre Nyquist"], "abstract": "In this paper, we consider large deviations for dynamical Schr\u00f6dinger problems, using the variational approach developed by Dupuis, Ellis, Budhiraja, and others. Recent results on scaled families of Schr\u00f6dinger problems, in particular by Bernton, Ghosal, and Nutz, and the authors, have established large deviation principles for the static problem. For the dynamic problem, only the case with a scaled Brownian motion reference process has been explored by Kato.\n  Here, we derive large deviation results using the variational approach, with the aim of going beyond the Brownian reference dynamics considered by Kato. Specifically, we develop a uniform on compacts Laplace principle for bridge processes conditioned on their endpoints. When combined with existing results for the static problem, this leads to a large deviation principle for the corresponding (dynamic) Schr\u00f6dinger bridge. In addition to the specific results of the paper, our work puts such large deviation questions into the weak convergence framework, and we conjecture that the results can be extended to cover also more involved types of reference dynamics. Specifically, we provide an outlook on applying the result to reflected Schr\u00f6dinger bridges.", "arxiv_id": "2511.14757v1", "url": "http://arxiv.org/abs/2511.14757v1", "published_date": "2025-11-18T18:58:14+00:00", "summary": "This paper investigates large deviations for dynamic Schr\u00f6dinger problems using the weak convergence (variational) approach pioneered by Dupuis, Ellis, Budhiraja, and colleagues. By extending existing results beyond scaled Brownian reference dynamics, the authors establish a uniform Laplace principle for bridge processes, enabling large deviation principles for dynamic Schr\u00f6dinger bridges. The work also suggests that the methodology can be adapted for more complex dynamics, such as reflected Schr\u00f6dinger bridges.", "tags": ["large deviations", "Schr\u00f6dinger bridge", "weak convergence", "variational methods", "stochastic processes", "Laplace principle", "dynamic optimal transport"], "questions_answered": ["How can large deviations for dynamic Schr\u00f6dinger problems be analyzed using weak convergence methods?", "What is the scope of the variational approach in extending large deviation principles beyond Brownian reference dynamics?", "Can the Laplace principle be established uniformly on compacts for conditioned bridge processes?", "What are the potential extensions to more involved reference dynamics in Schr\u00f6dinger bridge problems?"], "key_findings": ["A uniform on compacts Laplace principle is derived for bridge processes conditioned on endpoints, enabling large deviation results for dynamic Schr\u00f6dinger bridges.", "The weak convergence/variational approach is shown to be effective for dynamic problems, extending prior work focused on static cases.", "The results open the door for future analysis of large deviations in Schr\u00f6dinger problems with more general reference processes, including reflected Schr\u00f6dinger bridges."], "relevancy_score": 6.0, "interesting_score": 7.0, "ingested_at": "2025-11-19T14:36:26.855897"}, {"type": "paper", "id": "c92f8ddf982e1264c8ed67200007c483", "title": "Observation of critical scaling in the Bose gas universality class", "authors": ["Leon Kleebank", "Frank Vewinger", "Arturo Camacho-Guardian", "Victor Romero-Roch\u00edn", "Rosario Paredes", "Martin Weitz", "Julian Schmitt"], "abstract": "Critical exponents characterize the divergent scaling of thermodynamic quantities near phase transitions and allow for the classification of physical systems into universality classes. While quantum gases thermalizing by interparticle interactions fall into the XY model universality class, the ideal Bose gas has been predicted to form a distinct universality class whose signatures have not yet been revealed experimentally. Here, we report the observation of critical scaling in a two-dimensional quantum gas of essentially noninteracting photons, which thermalize by radiative contact to a reservoir of molecules inside a microcavity. By measuring the spatial correlations near the condensation transition, we determine the critical exponent for the correlation length to be $\u03bd= 0.52(3)$. Our results constitute a first experimental test of the long-standing scaling predictions for the Bose gas universality class.", "arxiv_id": "2511.14754v1", "url": "http://arxiv.org/abs/2511.14754v1", "published_date": "2025-11-18T18:53:38+00:00", "summary": "This paper reports the first experimental observation of critical scaling in a two-dimensional quantum gas of noninteracting photons, demonstrating that the ideal Bose gas forms a distinct universality class. By measuring spatial correlations close to the condensation transition, the authors determine a critical exponent for the correlation length, providing experimental verification of long-standing theoretical predictions for the Bose gas universality class.", "tags": ["phase transitions", "critical exponents", "universality classes", "quantum gases", "Bose-Einstein condensation", "photon thermalization", "statistical physics"], "questions_answered": ["Does the ideal Bose gas display a distinct universality class compared to interacting quantum gases?", "Can critical scaling be experimentally observed in a photon Bose gas?", "What is the critical exponent for the correlation length in the Bose gas universality class?"], "key_findings": ["Experimental observation of critical scaling in a two-dimensional photon Bose gas.", "Measurement of the critical exponent for the correlation length: \u03bd = 0.52(3).", "Confirmation that the ideal Bose gas forms its own universality class, distinct from the XY model."], "relevancy_score": 4.0, "interesting_score": 7.0, "ingested_at": "2025-11-19T14:36:29.403908"}, {"type": "paper", "id": "d72cf92fb1c15f5f0d47ba2f84d80f13", "title": "A Sequential Operator-Splitting Framework for Exploration of Nonconvex Trajectory Optimization Solution Spaces", "authors": ["Justin Ganiban", "Natalia Pavlasek", "Behcet Acikmese"], "abstract": "Trajectory optimization methods provide an efficient and reliable means of computing feasible trajectories in nonconvex solution spaces. However, a well-known limitation of these algorithms is that they are inherently local in nature, and typically converge to a solution in the neighborhood of their initial guess. This paper presents a sequential operator-splitting framework, based on the alternating direction method of multipliers (ADMM), aimed at promoting exploration within the sequential convex programming (SCP) framework. In particular, diverse initial solutions are modeled as agents within the consensus ADMM framework. Driving these agents toward consensus facilitates exploration of the nonconvex optimization landscape. Numerical simulations demonstrate that the proposed method consistently yields equivalent or lower-cost solutions compared to the standard SCP approach, with the same number of or fewer agents.", "arxiv_id": "2511.14752v1", "url": "http://arxiv.org/abs/2511.14752v1", "published_date": "2025-11-18T18:53:17+00:00", "summary": "This paper introduces a sequential operator-splitting framework, leveraging ADMM and consensus mechanisms, to enhance exploration in nonconvex trajectory optimization. By modeling diverse initial solutions as agents within the consensus ADMM setup, the method systematically explores multiple regions of the optimization landscape. Numerical simulations show that this approach consistently achieves solutions of equal or lower cost compared to standard sequential convex programming, often with fewer agents.", "tags": ["trajectory optimization", "nonconvex optimization", "sequential convex programming", "ADMM", "operator splitting", "consensus algorithms", "multi-agent exploration"], "questions_answered": ["How can local trajectory optimization methods better explore nonconvex solution spaces?", "Can agent-based consensus frameworks improve solution diversity in sequential convex programming?", "Does operator-splitting via ADMM yield more efficient or optimal trajectories compared to standard approaches?"], "key_findings": ["Modeling initial guesses as agents within a consensus ADMM framework facilitates deeper exploration of nonconvex optimization landscapes.", "The proposed operator-splitting framework consistently achieves equal or lower-cost solutions compared to standard SCP, with potentially fewer agents.", "The method demonstrates improved performance in numerical simulations, suggesting better utilization of diverse initializations in trajectory optimization."], "relevancy_score": 8.0, "interesting_score": 7.0, "ingested_at": "2025-11-19T14:36:31.956518"}], "links": []}